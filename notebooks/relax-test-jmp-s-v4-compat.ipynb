{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/net/csefiles/coc-fung-cluster/nima/shared/experiment-data/lltrainer/uirlcewv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "run_id = \"uirlcewv\"\n",
    "run_dir = Path(\n",
    "    f\"/net/csefiles/coc-fung-cluster/nima/shared/experiment-data/lltrainer/{run_id}/\"\n",
    ")\n",
    "assert (\n",
    "    run_dir.exists() and run_dir.is_dir()\n",
    "), f\"run_dir: {run_dir} does not exist or is not a directory\"\n",
    "print(run_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorBoard/TensorBoardX not found. Disabling TensorBoardLogger. Please install TensorBoard with `pip install tensorboard` or TensorBoardX with `pip install tensorboardx` to enable TensorBoard logging.\n",
      "Type checking the following modules: ('jmppeft',)\n",
      "/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/nshtrainer/model/config.py:1504: IdSeedWarning: BaseConfig._rng is None. The generated IDs will not be reproducible. To fix this, call BaseConfig.set_seed(...) before generating any IDs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MatbenchDiscoveryConfig(id='vbio0fwy', name='mptrj', name_parts=['jmps', 'bsz40', 'linrefenergy', 'lr8e-05', 'ln', 'direct', 'maceenergy', 'maceforce', 'rele', 'ec5.0', 'fc10.0', 'sc100.0', 'posaug_std0.01'], project='jmp_mptrj', directory=DirectoryConfig(project_root=PosixPath('/net/csefiles/coc-fung-cluster/nima/shared/experiment-data')), trainer=TrainerConfig(optimizer=OptimizationConfig(log_grad_norm=True, gradient_clipping=GradientClippingConfig(value=2.0, algorithm='value')), early_stopping=EarlyStoppingConfig(patience=50, min_lr=1e-08), precision='fp16-mixed', max_epochs=500, max_time='07:00:00:00', use_distributed_sampler=False, set_float32_matmul_precision='medium'), primary_metric=MetricConfig(name='matbench_discovery/force_mae', mode='min'), meta={'jmp_kind': 's'}, train_dataset=FinetuneMPTrjHuggingfaceDatasetConfig(split='train', energy_column_mapping={'y': 'corrected_total_energy_referenced', 'y_relaxed': 'corrected_total_energy_relaxed_referenced'}), val_dataset=FinetuneMPTrjHuggingfaceDatasetConfig(split='val', energy_column_mapping={'y': 'corrected_total_energy_referenced', 'y_relaxed': 'corrected_total_energy_relaxed_referenced'}), test_dataset=FinetuneMPTrjHuggingfaceDatasetConfig(split='test', energy_column_mapping={'y': 'corrected_total_energy_referenced', 'y_relaxed': 'corrected_total_energy_relaxed_referenced'}), optimizer=AdamWConfig(lr=8e-05, weight_decay=0.1, betas=(0.9, 0.95)), lr_scheduler=WarmupCosRLPConfig(warmup_epochs=1, max_epochs=128, warmup_start_lr_factor=0.1, min_lr_factor=0.5, rlp=RLPConfig(patience=5, factor=0.8)), embedding=EmbeddingConfig(num_elements=120, embedding_size=256), backbone=BackboneConfig(num_spherical=7, num_radial=128, num_blocks=4, emb_size_atom=256, emb_size_edge=512, emb_size_trip_in=64, emb_size_trip_out=64, emb_size_quad_in=32, emb_size_quad_out=32, emb_size_aint_in=64, emb_size_aint_out=64, emb_size_rbf=16, emb_size_cbf=16, emb_size_sbf=32, num_before_skip=2, num_after_skip=2, num_concat=1, num_atom=3, num_output_afteratom=3, num_atom_emb_layers=2, direct_forces=True, sbf={'name': 'legendre_outer'}, quad_interaction=True, atom_edge_interaction=True, edge_atom_interaction=True, atom_interaction=True, absolute_rbf_cutoff=12.0, dropout=None, edge_dropout=None, ln_per_layer=True, scale_factor_to_ln=True), batch_size=40, num_workers=7, graph_targets=[AllegroScalarTargetConfig(name='y', loss_coefficient=5.0, loss=MACEHuberEnergyLossConfig(delta=0.01), max_atomic_number=120, edge_level_energies=True), AllegroScalarTargetConfig(name='y_relaxed', loss_coefficient=2.5, loss=MACEHuberEnergyLossConfig(delta=0.01), max_atomic_number=120, edge_level_energies=True), DirectStressTargetConfig(name='stress', loss_coefficient=100.0, reduction='mean', loss=HuberLossConfig(delta=0.01))], node_targets=[NodeVectorTargetConfig(name='force', loss_coefficient=10.0, loss=MACEHuberLossConfig(delta=0.01))], parameter_specific_optimizers=[ParamSpecificOptimizerConfig(name='ln', paremeter_patterns=['backbone.h_lns.*', 'backbone.m_lns.*', 'backbone.*.scale*.ln.*'], optimizer=AdamWConfig(lr=0.00012000000000000002, weight_decay=0.1, betas=(0.9, 0.95)), lr_scheduler=WarmupCosRLPConfig(warmup_epochs=1, max_epochs=128, warmup_start_lr_factor=0.1, min_lr_factor=0.3333333333333333, rlp=RLPConfig(patience=5, factor=0.8))), ParamSpecificOptimizerConfig(name='embedding', paremeter_patterns=['embedding.*'], optimizer=AdamWConfig(lr=2.4e-05, weight_decay=0.1, betas=(0.9, 0.95)), lr_scheduler=WarmupCosRLPConfig(warmup_epochs=1, max_epochs=128, warmup_start_lr_factor=0.1, min_lr_factor=0.99, rlp=RLPConfig(patience=5, factor=0.8))), ParamSpecificOptimizerConfig(name='blocks_0', paremeter_patterns=['backbone.int_blocks.0.*', 'backbone.out_blocks.1.*', 'backbone.out_blocks.0.*'], optimizer=AdamWConfig(lr=2.4e-05, weight_decay=0.1, betas=(0.9, 0.95)), lr_scheduler=WarmupCosRLPConfig(warmup_epochs=1, max_epochs=128, warmup_start_lr_factor=0.1, min_lr_factor=0.99, rlp=RLPConfig(patience=5, factor=0.8))), ParamSpecificOptimizerConfig(name='blocks_1', paremeter_patterns=['backbone.int_blocks.1.*', 'backbone.out_blocks.2.*'], optimizer=AdamWConfig(lr=3.2000000000000005e-05, weight_decay=0.1, betas=(0.9, 0.95)), lr_scheduler=WarmupCosRLPConfig(warmup_epochs=1, max_epochs=128, warmup_start_lr_factor=0.1, min_lr_factor=0.99, rlp=RLPConfig(patience=5, factor=0.8))), ParamSpecificOptimizerConfig(name='blocks_2', paremeter_patterns=['backbone.int_blocks.2.*', 'backbone.out_blocks.3.*'], optimizer=AdamWConfig(lr=4.4000000000000006e-05, weight_decay=0.1, betas=(0.9, 0.95)), lr_scheduler=WarmupCosRLPConfig(warmup_epochs=1, max_epochs=128, warmup_start_lr_factor=0.1, min_lr_factor=0.9090909090909091, rlp=RLPConfig(patience=5, factor=0.8))), ParamSpecificOptimizerConfig(name='blocks_3', paremeter_patterns=['backbone.int_blocks.3.*', 'backbone.out_blocks.4.*'], optimizer=AdamWConfig(lr=5e-05, weight_decay=0.1, betas=(0.9, 0.95)), lr_scheduler=WarmupCosRLPConfig(warmup_epochs=1, max_epochs=128, warmup_start_lr_factor=0.1, min_lr_factor=0.8, rlp=RLPConfig(patience=5, factor=0.8))), ParamSpecificOptimizerConfig(name='y.scales', paremeter_patterns=['graph_outputs._module_dict.ft_mlp_y.per_atom_scales.*', 'graph_outputs._module_dict.ft_mlp_y.per_atom_shifts.*', 'graph_outputs._module_dict.ft_mlp_y.pairwise_scales.*'], optimizer=AdamWConfig(lr=8.000000000000001e-06, weight_decay=0.1, betas=(0.9, 0.95)), lr_scheduler=WarmupCosRLPConfig(warmup_epochs=1, max_epochs=128, warmup_start_lr_factor=0.1, min_lr_factor=0.99, rlp=RLPConfig(patience=5, factor=0.8))), ParamSpecificOptimizerConfig(name='y_relaxed.scales', paremeter_patterns=['graph_outputs._module_dict.ft_mlp_y_relaxed.per_atom_scales.*', 'graph_outputs._module_dict.ft_mlp_y_relaxed.per_atom_shifts.*', 'graph_outputs._module_dict.ft_mlp_y_relaxed.pairwise_scales.*'], optimizer=AdamWConfig(lr=8.000000000000001e-06, weight_decay=0.1, betas=(0.9, 0.95)), lr_scheduler=WarmupCosRLPConfig(warmup_epochs=1, max_epochs=128, warmup_start_lr_factor=0.1, min_lr_factor=0.99, rlp=RLPConfig(patience=5, factor=0.8)))], use_balanced_batch_sampler=True, ckpt_load=CheckpointLoadConfig(checkpoint=PretrainedCheckpointConfig(path=PosixPath('/net/csefiles/coc-fung-cluster/nima/shared/checkpoints/jmp-s.pt'))), pos_noise_augmentation=PositionNoiseAugmentationConfig(noise_std=0.01, system_corrupt_prob=0.75, atom_corrupt_prob=0.5), per_graph_radius_graph=True, ignore_graph_generation_errors=False, max_neighbors=MaxNeighbors(main=25, aeaint=20, qint=8, aint=1000))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_config():\n",
    "    from collections.abc import Callable\n",
    "    from pathlib import Path\n",
    "    from typing import Literal\n",
    "\n",
    "    import nshtrainer as nt\n",
    "    from jmppeft.configs.finetune.jmp_s import jmp_s_ft_config_\n",
    "    from jmppeft.modules import loss\n",
    "    from jmppeft.tasks.config import AdamWConfig\n",
    "    from jmppeft.tasks.finetune import base, output_head\n",
    "    from jmppeft.tasks.finetune import matbench_discovery as M\n",
    "    from jmppeft.utils.param_specific_util import (\n",
    "        make_parameter_specific_optimizer_config,\n",
    "        parameter_specific_optimizer_config,\n",
    "    )\n",
    "\n",
    "    jmp_s_ckpt_path = Path(\n",
    "        \"/net/csefiles/coc-fung-cluster/nima/shared/checkpoints/jmp-s.pt\"\n",
    "    )\n",
    "\n",
    "    # Set this to None if you want the run logs to be saved in the current directory\n",
    "    project_root: Path | None = Path(\n",
    "        \"/net/csefiles/coc-fung-cluster/nima/shared/experiment-data/\"\n",
    "    )\n",
    "    project_root.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    def jmp_s_(config: base.FinetuneConfigBase):\n",
    "        ckpt_path = jmp_s_ckpt_path\n",
    "        assert ckpt_path.exists(), f\"Checkpoint not found: {ckpt_path}\"\n",
    "\n",
    "        jmp_s_ft_config_(config)\n",
    "        config.ckpt_load.checkpoint = base.PretrainedCheckpointConfig(\n",
    "            path=ckpt_path, ema=True\n",
    "        )\n",
    "\n",
    "        config.meta[\"jmp_kind\"] = \"s\"\n",
    "        config.name_parts.append(\"jmps\")\n",
    "\n",
    "    def parameter_specific_optimizers_(config: base.FinetuneConfigBase):\n",
    "        if config.parameter_specific_optimizers is None:\n",
    "            config.parameter_specific_optimizers = []\n",
    "\n",
    "        match config.meta[\"jmp_kind\"]:\n",
    "            case \"l\":\n",
    "                config.parameter_specific_optimizers.extend(\n",
    "                    make_parameter_specific_optimizer_config(\n",
    "                        config,\n",
    "                        config.backbone.num_blocks,\n",
    "                        {\n",
    "                            \"embedding\": 0.3,\n",
    "                            \"blocks_0\": 0.55,\n",
    "                            \"blocks_1\": 0.40,\n",
    "                            \"blocks_2\": 0.30,\n",
    "                            \"blocks_3\": 0.40,\n",
    "                            \"blocks_4\": 0.55,\n",
    "                            \"blocks_5\": 0.625,\n",
    "                        },\n",
    "                    )\n",
    "                )\n",
    "            case \"s\":\n",
    "                config.parameter_specific_optimizers.extend(\n",
    "                    make_parameter_specific_optimizer_config(\n",
    "                        config,\n",
    "                        config.backbone.num_blocks,\n",
    "                        {\n",
    "                            \"embedding\": 0.3,\n",
    "                            \"blocks_0\": 0.30,\n",
    "                            \"blocks_1\": 0.40,\n",
    "                            \"blocks_2\": 0.55,\n",
    "                            \"blocks_3\": 0.625,\n",
    "                        },\n",
    "                    )\n",
    "                )\n",
    "            case _:\n",
    "                raise ValueError(f\"Invalid jmp_kind: {config.meta['jmp_kind']}\")\n",
    "\n",
    "    def parameter_specific_optimizers_energy_references_(\n",
    "        config: base.FinetuneConfigBase,\n",
    "        lr_multiplier: float = 0.1,\n",
    "    ):\n",
    "        if not config.parameter_specific_optimizers:\n",
    "            config.parameter_specific_optimizers = []\n",
    "\n",
    "        if energy_ref_heads := [\n",
    "            t\n",
    "            for t in config.graph_targets\n",
    "            if isinstance(t, output_head.ReferencedScalarTargetConfig)\n",
    "        ]:\n",
    "            config.parameter_specific_optimizers.extend(\n",
    "                parameter_specific_optimizer_config(\n",
    "                    config,\n",
    "                    [\n",
    "                        {\n",
    "                            \"name\": f\"{energy_ref_head.name}.ref\",\n",
    "                            \"lr_multiplier\": lr_multiplier,\n",
    "                            \"parameter_patterns\": [\n",
    "                                f\"graph_outputs._module_dict.ft_mlp_{energy_ref_head.name}.references.*\"\n",
    "                            ],\n",
    "                        }\n",
    "                        for energy_ref_head in energy_ref_heads\n",
    "                    ],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        elif allegro_heads := [\n",
    "            t\n",
    "            for t in config.graph_targets\n",
    "            if isinstance(t, output_head.AllegroScalarTargetConfig)\n",
    "        ]:\n",
    "            config.parameter_specific_optimizers.extend(\n",
    "                parameter_specific_optimizer_config(\n",
    "                    config,\n",
    "                    [\n",
    "                        {\n",
    "                            \"name\": f\"{h.name}.scales\",\n",
    "                            \"lr_multiplier\": lr_multiplier,\n",
    "                            \"parameter_patterns\": [\n",
    "                                f\"graph_outputs._module_dict.ft_mlp_{h.name}.per_atom_scales.*\",\n",
    "                                f\"graph_outputs._module_dict.ft_mlp_{h.name}.per_atom_shifts.*\",\n",
    "                                *(\n",
    "                                    [\n",
    "                                        f\"graph_outputs._module_dict.ft_mlp_{h.name}.pairwise_scales.*\"\n",
    "                                    ]\n",
    "                                    if h.edge_level_energies\n",
    "                                    else []\n",
    "                                ),\n",
    "                            ],\n",
    "                        }\n",
    "                        for h in allegro_heads\n",
    "                    ],\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"No energy reference or allegro heads found\")\n",
    "\n",
    "    def direct_(config: base.FinetuneConfigBase):\n",
    "        config.backbone.regress_forces = True\n",
    "        config.backbone.direct_forces = True\n",
    "        config.backbone.regress_energy = True\n",
    "        config.name_parts.append(\"direct\")\n",
    "\n",
    "    def ln_(\n",
    "        config: base.FinetuneConfigBase,\n",
    "        *,\n",
    "        lr_multiplier: float | None,\n",
    "    ):\n",
    "        config.backbone.ln_per_layer = True\n",
    "        config.backbone.scale_factor_to_ln = True\n",
    "\n",
    "        if lr_multiplier is not None:\n",
    "            if config.parameter_specific_optimizers is None:\n",
    "                config.parameter_specific_optimizers = []\n",
    "\n",
    "            config.parameter_specific_optimizers = [\n",
    "                *parameter_specific_optimizer_config(\n",
    "                    config,\n",
    "                    [\n",
    "                        {\n",
    "                            \"name\": \"ln\",\n",
    "                            \"lr_multiplier\": lr_multiplier,\n",
    "                            \"parameter_patterns\": [\n",
    "                                \"backbone.h_lns.*\",\n",
    "                                \"backbone.m_lns.*\",\n",
    "                                \"backbone.*.scale*.ln.*\",\n",
    "                            ],\n",
    "                        }\n",
    "                    ],\n",
    "                ),\n",
    "                *config.parameter_specific_optimizers,\n",
    "            ]\n",
    "\n",
    "        config.name_parts.append(\"ln\")\n",
    "\n",
    "    def pos_aug_(config: base.FinetuneConfigBase, *, std: float):\n",
    "        config.pos_noise_augmentation = base.PositionNoiseAugmentationConfig(\n",
    "            system_corrupt_prob=0.75,\n",
    "            atom_corrupt_prob=0.5,\n",
    "            noise_std=std,\n",
    "        )\n",
    "        config.name_parts.append(f\"posaug_std{std}\")\n",
    "\n",
    "    def data_config_(\n",
    "        config: M.MatbenchDiscoveryConfig,\n",
    "        *,\n",
    "        batch_size: int,\n",
    "        reference: bool,\n",
    "    ):\n",
    "        config.batch_size = batch_size\n",
    "        config.name_parts.append(f\"bsz{batch_size}\")\n",
    "\n",
    "        def dataset_fn(split: Literal[\"train\", \"val\", \"test\"]):\n",
    "            return base.FinetuneMPTrjHuggingfaceDatasetConfig(\n",
    "                split=split,\n",
    "                energy_column_mapping={\n",
    "                    \"y\": \"corrected_total_energy_referenced\",\n",
    "                    \"y_relaxed\": \"corrected_total_energy_relaxed_referenced\",\n",
    "                }\n",
    "                if reference\n",
    "                else {\n",
    "                    \"y\": \"corrected_total_energy\",\n",
    "                    \"y_relaxed\": \"corrected_total_energy_relaxed\",\n",
    "                },\n",
    "            )\n",
    "\n",
    "        config.train_dataset = dataset_fn(\"train\")\n",
    "        config.val_dataset = dataset_fn(\"val\")\n",
    "        config.test_dataset = dataset_fn(\"test\")\n",
    "\n",
    "        if reference:\n",
    "            config.name_parts.append(\"linrefenergy\")\n",
    "        else:\n",
    "            config.name_parts.append(\"totalenergy\")\n",
    "\n",
    "        # Set data config\n",
    "        config.num_workers = 7\n",
    "\n",
    "        # Balanced batch sampler\n",
    "        config.use_balanced_batch_sampler = True\n",
    "        config.trainer.use_distributed_sampler = False\n",
    "\n",
    "    def output_heads_config_(\n",
    "        config: M.MatbenchDiscoveryConfig,\n",
    "        *,\n",
    "        relaxed_energy: bool,\n",
    "        mace_energy_loss: bool,\n",
    "        mace_force_loss: bool,\n",
    "        energy_coefficient: float,\n",
    "        force_coefficient: float,\n",
    "        stress_coefficient: float,\n",
    "    ):\n",
    "        energy_loss = loss.HuberLossConfig(delta=0.01)\n",
    "        if mace_energy_loss:\n",
    "            energy_loss = loss.MACEHuberEnergyLossConfig(delta=0.01)\n",
    "            config.name_parts.append(\"maceenergy\")\n",
    "\n",
    "        force_loss = loss.HuberLossConfig(delta=0.01)\n",
    "        if mace_force_loss:\n",
    "            force_loss = loss.MACEHuberLossConfig(delta=0.01)\n",
    "            config.name_parts.append(\"maceforce\")\n",
    "\n",
    "        # Energy head\n",
    "        config.graph_targets.append(\n",
    "            output_head.AllegroScalarTargetConfig(\n",
    "                name=\"y\",\n",
    "                loss_coefficient=energy_coefficient,\n",
    "                loss=energy_loss.model_copy(),\n",
    "                reduction=\"sum\",\n",
    "                max_atomic_number=config.backbone.num_elements,\n",
    "                edge_level_energies=True,\n",
    "            )\n",
    "        )\n",
    "        if relaxed_energy:\n",
    "            # Relaxed Energy head\n",
    "            config.graph_targets.append(\n",
    "                output_head.AllegroScalarTargetConfig(\n",
    "                    name=\"y_relaxed\",\n",
    "                    loss_coefficient=energy_coefficient / 2.0,\n",
    "                    loss=energy_loss.model_copy(),\n",
    "                    reduction=\"sum\",\n",
    "                    max_atomic_number=config.backbone.num_elements,\n",
    "                    edge_level_energies=True,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            config.name_parts.append(\"rele\")\n",
    "        # Stress head\n",
    "        config.graph_targets.append(\n",
    "            output_head.DirectStressTargetConfig(\n",
    "                name=\"stress\",\n",
    "                loss_coefficient=stress_coefficient,\n",
    "                loss=loss.HuberLossConfig(delta=0.01),\n",
    "                reduction=\"mean\",\n",
    "            )\n",
    "        )\n",
    "        # Force head\n",
    "        config.node_targets.append(\n",
    "            output_head.NodeVectorTargetConfig(\n",
    "                name=\"force\",\n",
    "                loss_coefficient=force_coefficient,\n",
    "                loss=force_loss,\n",
    "                reduction=\"sum\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        config.name_parts.append(f\"ec{energy_coefficient}\")\n",
    "        config.name_parts.append(f\"fc{force_coefficient}\")\n",
    "        config.name_parts.append(f\"sc{stress_coefficient}\")\n",
    "\n",
    "    def optimization_config_(\n",
    "        config: M.MatbenchDiscoveryConfig,\n",
    "        *,\n",
    "        lr: float,\n",
    "    ):\n",
    "        config.optimizer = AdamWConfig(\n",
    "            lr=lr,\n",
    "            amsgrad=False,\n",
    "            betas=(0.9, 0.95),\n",
    "            weight_decay=0.1,\n",
    "        )\n",
    "        config.lr_scheduler = base.WarmupCosRLPConfig(\n",
    "            warmup_epochs=1,\n",
    "            warmup_start_lr_factor=1.0e-1,\n",
    "            should_restart=False,\n",
    "            max_epochs=128,\n",
    "            min_lr_factor=0.5,\n",
    "            rlp=base.RLPConfig(patience=5, factor=0.8),\n",
    "        )\n",
    "        config.trainer.optimizer.gradient_clipping = nt.model.GradientClippingConfig(\n",
    "            value=2.0,\n",
    "            algorithm=\"value\",\n",
    "        )\n",
    "\n",
    "        config.name_parts.append(f\"lr{lr}\")\n",
    "\n",
    "    def create_config(config_fn: Callable[[M.MatbenchDiscoveryConfig], None]):\n",
    "        config = M.MatbenchDiscoveryConfig.draft()\n",
    "\n",
    "        config.trainer.precision = \"16-mixed-auto\"\n",
    "        config.trainer.set_float32_matmul_precision = \"medium\"\n",
    "\n",
    "        config.project = \"jmp_mptrj\"\n",
    "        config.name = \"mptrj\"\n",
    "        config_fn(config)\n",
    "        config.backbone.qint_tags = [0, 1, 2]\n",
    "\n",
    "        config.primary_metric = nt.MetricConfig(\n",
    "            name=\"matbench_discovery/force_mae\", mode=\"min\"\n",
    "        )\n",
    "\n",
    "        if project_root:\n",
    "            config.with_project_root_(project_root)\n",
    "        return config\n",
    "\n",
    "    config = create_config(jmp_s_)\n",
    "    config.parameter_specific_optimizers = []\n",
    "    config.max_neighbors = M.MaxNeighbors(main=25, aeaint=20, aint=1000, qint=8)\n",
    "    config.cutoffs = M.Cutoffs.from_constant(12.0)\n",
    "    data_config_(config, reference=True, batch_size=40)\n",
    "    optimization_config_(config, lr=8.0e-5)\n",
    "    ln_(config, lr_multiplier=1.5)\n",
    "    direct_(config=config)\n",
    "    output_heads_config_(\n",
    "        config,\n",
    "        relaxed_energy=True,\n",
    "        mace_energy_loss=True,\n",
    "        mace_force_loss=True,\n",
    "        energy_coefficient=5.0,\n",
    "        force_coefficient=10.0,\n",
    "        stress_coefficient=100.0,\n",
    "    )\n",
    "    parameter_specific_optimizers_(config)\n",
    "    parameter_specific_optimizers_energy_references_(config, lr_multiplier=0.1)\n",
    "    pos_aug_(config, std=0.01)\n",
    "    config.per_graph_radius_graph = True\n",
    "    config.ignore_graph_generation_errors = False\n",
    "\n",
    "    config = config.finalize()\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "config = make_config()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/net/csefiles/coc-fung-cluster/nima/shared/experiment-data/lltrainer/uirlcewv/log/csv/csv/mptrj-jmps-bsz16-linrefenergy-lr8e-05-ln-direct-maceenergy-maceforce-rele-ec2.0-fc10.0-sc100.0-posaug_std0.01/uirlcewv/hparams.yaml\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "config_updated = config\n",
    "\n",
    "hparams_file = next(run_dir.glob(\"./log/csv/csv/*/*/hparams.yaml\"))\n",
    "print(hparams_file)\n",
    "\n",
    "key_keys = (\n",
    "    \"backbone\",\n",
    "    \"embedding\",\n",
    "    \"output\",\n",
    "    \"graph_targets\",\n",
    "    \"node_targets\",\n",
    "    \"train_dataset\",\n",
    "    \"val_dataset\",\n",
    "    \"test_dataset\",\n",
    "    \"id\",\n",
    "    \"name\",\n",
    "    \"name_parts\",\n",
    "    # \"predict_dataset\",\n",
    ")\n",
    "\n",
    "hparams = yaml.unsafe_load(hparams_file.read_text())\n",
    "\n",
    "# Update the config with the hparams\n",
    "for key in key_keys:\n",
    "    assert (value := hparams.get(key)), f\"{key} not found in hparams\"\n",
    "\n",
    "    config_dict = config_updated.model_dump(round_trip=True)\n",
    "    config_dict[key] = value\n",
    "    config_updated = config_updated.model_validate(config_dict, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LL_DISABLE_TYPECHECKING\"] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.no_grad().__enter__()\n",
    "torch.inference_mode().__enter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/net/csefiles/coc-fung-cluster/nima/shared/experiment-data/lltrainer/uirlcewv/checkpoint/latest_epoch31_step724384.ckpt')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ckpt_path = run_dir / \"checkpoint\" / \"last.ckpt\"\n",
    "ckpt_path = next(run_dir.glob(\"checkpoint/latest_*.ckpt\"))\n",
    "# If the file is a symlink, get the target\n",
    "if ckpt_path.is_symlink():\n",
    "    print(f\"Symlink found {ckpt_path} => {ckpt_path.resolve()}\")\n",
    "    ckpt_path = ckpt_path.resolve()\n",
    "\n",
    "ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading 'wbm_summary' from cached file at '/nethome/nsg6/.cache/matbench-discovery/1.0.0/wbm/2023-12-13-wbm-summary.csv.gz'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<jmppeft.datasets.mpd_is2re.MatBenchDiscoveryIS2REDataset at 0x7f402814cd90>,\n",
       " 256963)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jmppeft.tasks.finetune.base import FinetuneMatBenchDiscoveryIS2REDatasetConfig\n",
    "\n",
    "dataset_config = FinetuneMatBenchDiscoveryIS2REDatasetConfig(\n",
    "    # sample_n=DatasetSampleNConfig(sample_n=16, seed=42)\n",
    ")\n",
    "print(dataset_config)\n",
    "\n",
    "dataset_og = dataset_config.create_dataset()\n",
    "dataset_og, len(dataset_og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NSHRUNNER_SESSION_DIR is not set. Skipping symlink creation.\n",
      "NSHRUNNER_SESSION_DIR is not set. Skipping symlink creation.\n",
      "NSHRUNNER_SESSION_DIR is not set. Skipping symlink creation.\n",
      "NSHRUNNER_SESSION_DIR is not set. Skipping symlink creation.\n",
      "Using regular backbone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unrecognized arguments:  dict_keys(['name', 'learnable_rbf', 'learnable_rbf_stds', 'unique_basis_per_layer', 'dropout', 'edge_dropout', 'ln_per_layer', 'scale_factor_to_ln'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Constructed backbone with dlora=None\n",
      "Freezing 0 parameters (0.00%) out of 43,146,824 total parameters (43,146,824 trainable)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MatbenchDiscoveryModel(config=MatbenchDiscoveryConfig(name=mptrj-jmps-bsz16-linrefenergy-lr8e-05-ln-direct-maceenergy-maceforce-rele-ec2.0-fc10.0-sc100.0-posaug_std0.01, project=jmp_mptrj), device=cuda:0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jmppeft.tasks.finetune import matbench_discovery as M\n",
    "\n",
    "default_dtype = torch.float32\n",
    "ckpt = torch.load(ckpt_path, map_location=\"cuda\")\n",
    "\n",
    "model = M.MatbenchDiscoveryModel(config_updated)\n",
    "model = model.to(default_dtype).cuda().eval()\n",
    "model.load_state_dict(ckpt[\"state_dict\"])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'pos'</span>: tensor<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">]</span> <span style=\"color: #808000; text-decoration-color: #808000\">n</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span> x∈<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4.287</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.937</span><span style=\"font-weight: bold\">]</span> <span style=\"color: #808000; text-decoration-color: #808000\">μ</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.412</span> <span style=\"color: #808000; text-decoration-color: #808000\">σ</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.423</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'wbm-3-72883'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'atomic_numbers'</span>: tensor<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span><span style=\"font-weight: bold\">]</span> i64 x∈<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79</span><span style=\"font-weight: bold\">]</span> <span style=\"color: #808000; text-decoration-color: #808000\">μ</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">62.000</span> <span style=\"color: #808000; text-decoration-color: #808000\">σ</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.269</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cell'</span>: tensor<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">]</span> <span style=\"color: #808000; text-decoration-color: #808000\">n</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> x∈<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-3.509</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.938</span><span style=\"font-weight: bold\">]</span> <span style=\"color: #808000; text-decoration-color: #808000\">μ</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.065</span> <span style=\"color: #808000; text-decoration-color: #808000\">σ</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.112</span> <span style=\"font-weight: bold\">[[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.029</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-3.509</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.037</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.674</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-3.509</span><span style=\"font-weight: bold\">]</span>, \n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.938</span><span style=\"font-weight: bold\">]]]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'y_formation'</span>: tensor<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.236</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'y_formation_correction'</span>: tensor<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'y_above_hull'</span>: tensor<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.093</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'natoms'</span>: tensor<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span> i64 <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'pos_noise'</span>: tensor<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">]</span> <span style=\"color: #808000; text-decoration-color: #808000\">n</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">all_zeros</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'tags'</span>: tensor<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span><span style=\"font-weight: bold\">]</span> i64 x∈<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span> <span style=\"color: #808000; text-decoration-color: #808000\">μ</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.000</span> <span style=\"color: #808000; text-decoration-color: #808000\">σ</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'fixed'</span>: tensor<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span><span style=\"font-weight: bold\">]</span> bool <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">all_zeros</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'batch'</span>: tensor<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span><span style=\"font-weight: bold\">]</span> i64 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">all_zeros</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ptr'</span>: tensor<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span> i64 <span style=\"color: #808000; text-decoration-color: #808000\">μ</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.500</span> <span style=\"color: #808000; text-decoration-color: #808000\">σ</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.778</span> <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">66</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'pos'\u001b[0m: tensor\u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m \u001b[33mn\u001b[0m=\u001b[1;36m33\u001b[0m x∈\u001b[1m[\u001b[0m\u001b[1;36m-4.287\u001b[0m, \u001b[1;36m6.937\u001b[0m\u001b[1m]\u001b[0m \u001b[33mμ\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1;36m.412\u001b[0m \u001b[33mσ\u001b[0m=\u001b[1;36m2\u001b[0m\u001b[1;36m.423\u001b[0m,\n",
       "    \u001b[32m'id'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'wbm-3-72883'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'atomic_numbers'\u001b[0m: tensor\u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1m]\u001b[0m i64 x∈\u001b[1m[\u001b[0m\u001b[1;36m50\u001b[0m, \u001b[1;36m79\u001b[0m\u001b[1m]\u001b[0m \u001b[33mμ\u001b[0m=\u001b[1;36m62\u001b[0m\u001b[1;36m.000\u001b[0m \u001b[33mσ\u001b[0m=\u001b[1;36m14\u001b[0m\u001b[1;36m.269\u001b[0m,\n",
       "    \u001b[32m'cell'\u001b[0m: tensor\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m \u001b[33mn\u001b[0m=\u001b[1;36m9\u001b[0m x∈\u001b[1m[\u001b[0m\u001b[1;36m-3.509\u001b[0m, \u001b[1;36m6.938\u001b[0m\u001b[1m]\u001b[0m \u001b[33mμ\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1;36m.065\u001b[0m \u001b[33mσ\u001b[0m=\u001b[1;36m4\u001b[0m\u001b[1;36m.112\u001b[0m \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m6.029\u001b[0m, \u001b[1;36m0\u001b[0m., \u001b[1;36m-3.509\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1;36m-2.037\u001b[0m, \u001b[1;36m5.674\u001b[0m, \u001b[1;36m-3.509\u001b[0m\u001b[1m]\u001b[0m, \n",
       "\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m., \u001b[1;36m0\u001b[0m., \u001b[1;36m6.938\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'y_formation'\u001b[0m: tensor\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m\u001b[1;36m-0.236\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'y_formation_correction'\u001b[0m: tensor\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'y_above_hull'\u001b[0m: tensor\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m\u001b[1;36m0.093\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'natoms'\u001b[0m: tensor\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m i64 \u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'pos_noise'\u001b[0m: tensor\u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m \u001b[33mn\u001b[0m=\u001b[1;36m33\u001b[0m \u001b[38;2;127;127;127mall_zeros\u001b[0m,\n",
       "    \u001b[32m'tags'\u001b[0m: tensor\u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1m]\u001b[0m i64 x∈\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m \u001b[33mμ\u001b[0m=\u001b[1;36m2\u001b[0m\u001b[1;36m.000\u001b[0m \u001b[33mσ\u001b[0m=\u001b[1;36m0\u001b[0m.,\n",
       "    \u001b[32m'fixed'\u001b[0m: tensor\u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1m]\u001b[0m bool \u001b[38;2;127;127;127mall_zeros\u001b[0m,\n",
       "    \u001b[32m'batch'\u001b[0m: tensor\u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1m]\u001b[0m i64 \u001b[38;2;127;127;127mall_zeros\u001b[0m,\n",
       "    \u001b[32m'ptr'\u001b[0m: tensor\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m i64 \u001b[33mμ\u001b[0m=\u001b[1;36m5\u001b[0m\u001b[1;36m.500\u001b[0m \u001b[33mσ\u001b[0m=\u001b[1;36m7\u001b[0m\u001b[1;36m.778\u001b[0m \u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m11\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n",
       "\u001b[1m{\u001b[0m\u001b[1;36m66\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[1;36m50\u001b[0m: \u001b[1;36m6\u001b[0m, \u001b[1;36m79\u001b[0m: \u001b[1;36m4\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import jmppeft.modules.dataset.dataset_transform as DT\n",
    "import nshutils\n",
    "import rich\n",
    "import torch.utils._pytree as tree\n",
    "from lightning.fabric.utilities.apply_func import move_data_to_device\n",
    "from torch_geometric.data import Batch, Data\n",
    "\n",
    "nshutils.pretty()\n",
    "\n",
    "\n",
    "def data_transform(data: Data):\n",
    "    data = model.data_transform(data)\n",
    "    data = Data.from_dict(\n",
    "        tree.tree_map(\n",
    "            lambda x: x.type(default_dtype)\n",
    "            if torch.is_tensor(x) and torch.is_floating_point(x)\n",
    "            else x,\n",
    "            data.to_dict(),\n",
    "        )\n",
    "    )\n",
    "    return data\n",
    "\n",
    "\n",
    "def composition(data: Batch):\n",
    "    return dict(Counter(data.atomic_numbers.tolist()))\n",
    "\n",
    "\n",
    "num_items = 1024\n",
    "\n",
    "dataset = DT.transform(dataset_og, data_transform)\n",
    "dataset = DT.sample_n_transform(dataset, n=num_items, seed=42)\n",
    "\n",
    "\n",
    "idx = 32\n",
    "data = Batch.from_data_list([dataset[idx]])\n",
    "rich.print(data.to_dict(), composition(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[20:14:09] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> TensorBoard/TensorBoardX not found. Disabling TensorBoardLogger. Please install   <a href=\"file:///net/csefiles/coc-fung-cluster/nima/shared/repositories/ll/src/ll/model/config.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">config.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///net/csefiles/coc-fung-cluster/nima/shared/repositories/ll/src/ll/model/config.py#532\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">532</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         TensorBoard with `pip install tensorboard` or TensorBoardX with `pip install      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         tensorboardx` to enable TensorBoard logging.                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[20:14:09]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m TensorBoard/TensorBoardX not found. Disabling TensorBoardLogger. Please install   \u001b]8;id=979905;file:///net/csefiles/coc-fung-cluster/nima/shared/repositories/ll/src/ll/model/config.py\u001b\\\u001b[2mconfig.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=314190;file:///net/csefiles/coc-fung-cluster/nima/shared/repositories/ll/src/ll/model/config.py#532\u001b\\\u001b[2m532\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         TensorBoard with `pip install tensorboard` or TensorBoardX with `pip install      \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         tensorboardx` to enable TensorBoard logging.                                      \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'energy': tensor[1] cuda:0 [0.111],\n",
       " 'forces': tensor[11, 3] n=33 x∈[-0.454, 0.454] μ=0.001 σ=0.216 cuda:0,\n",
       " 'stress': tensor[1, 3, 3] n=9 x∈[-0.107, -0.003] μ=-0.038 σ=0.051 cuda:0 [[[-0.103, -0.003, -0.003], [-0.003, -0.105, -0.005], [-0.003, -0.005, -0.107]]]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from jmppeft.modules.relaxer import ModelOutput, Relaxer\n",
    "from matbench_discovery.energy import get_e_form_per_atom\n",
    "\n",
    "USE_Y_RELAXED = False\n",
    "LINREF = np.load(\n",
    "    \"/net/csefiles/coc-fung-cluster/nima/shared/repositories/jmp-peft/notebooks/mptrj_linref.npy\"\n",
    ")\n",
    "\n",
    "\n",
    "def model_fn(data, initial_data, *, use_y_relaxed: bool = USE_Y_RELAXED) -> ModelOutput:\n",
    "    model_out = model.forward_denormalized(data)\n",
    "\n",
    "    energy = model_out[\"y_relaxed\"] if use_y_relaxed else model_out[\"y\"]\n",
    "    # energy = model_out[\"y\"]\n",
    "    # relaxed_energy = model_out[\"y_relaxed\"]\n",
    "    forces = model_out[\"force\"]\n",
    "    stress = model_out[\"stress\"]\n",
    "\n",
    "    # Undo the linref\n",
    "    if LINREF is not None:\n",
    "        energy = energy + LINREF[data.atomic_numbers.cpu().numpy()].sum()\n",
    "\n",
    "    # JMP-S v2 energy is corrected_energy, i.e., DFT total energy\n",
    "    # This energy is now DFT total energy, we need to convert it to formation energy per atom\n",
    "    energy = get_e_form_per_atom(\n",
    "        {\n",
    "            \"composition\": composition(data),\n",
    "            \"energy\": energy,\n",
    "        }\n",
    "    )\n",
    "    assert isinstance(energy, torch.Tensor)\n",
    "    # assert isinstance(relaxed_energy, torch.Tensor)\n",
    "\n",
    "    # Add the correction factor\n",
    "    if False:\n",
    "        energy += initial_data.y_formation_correction.item()\n",
    "\n",
    "    # energy, relaxed_energy = tree.tree_map(\n",
    "    #     lambda energy: energy.view(1), (energy, relaxed_energy)\n",
    "    # )\n",
    "    energy = energy.view(1)\n",
    "    forces = forces.view(-1, 3)\n",
    "    stress = stress.view(1, 3, 3) if stress.numel() == 9 else stress.view(1, 6)\n",
    "\n",
    "    return {\n",
    "        \"energy\": energy,\n",
    "        # \"relaxed_energy\": relaxed_energy,\n",
    "        \"forces\": forces,\n",
    "        \"stress\": stress,\n",
    "    }\n",
    "\n",
    "\n",
    "data = move_data_to_device(data, model.device)\n",
    "model_fn(data, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">tensor<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span> cu<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">da:0</span> <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.236</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "tensor\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m cu\u001b[1;92mda:0\u001b[0m \u001b[1m[\u001b[0m\u001b[1;36m-0.236\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Step     Time          Energy          fmax\n",
      "FIRE:    0 20:14:10        0.111085        2.534322\n",
      "FIRE:    1 20:14:10       -0.033397        1.314817\n",
      "FIRE:    2 20:14:10       -0.104730        0.361149\n",
      "FIRE:    3 20:14:10       -0.071463        0.937753\n",
      "FIRE:    4 20:14:10       -0.076991        0.889091\n",
      "FIRE:    5 20:14:11       -0.086585        0.788414\n",
      "FIRE:    6 20:14:11       -0.097697        0.627135\n",
      "FIRE:    7 20:14:11       -0.107140        0.400099\n",
      "FIRE:    8 20:14:11       -0.112394        0.335226\n",
      "FIRE:    9 20:14:11       -0.112895        0.315883\n",
      "FIRE:   10 20:14:11       -0.110406        0.362677\n",
      "FIRE:   11 20:14:11       -0.105542        0.567738\n",
      "FIRE:   12 20:14:12       -0.104622        0.653812\n",
      "FIRE:   13 20:14:12       -0.113047        0.572379\n",
      "FIRE:   14 20:14:12       -0.124802        0.323620\n",
      "FIRE:   15 20:14:12       -0.135171        0.302931\n",
      "FIRE:   16 20:14:12       -0.139262        0.339625\n",
      "FIRE:   17 20:14:12       -0.141019        0.430812\n",
      "FIRE:   18 20:14:12       -0.147456        0.360977\n",
      "FIRE:   19 20:14:12       -0.157865        0.236124\n",
      "FIRE:   20 20:14:13       -0.158378        0.300203\n",
      "FIRE:   21 20:14:13       -0.165005        0.399013\n",
      "FIRE:   22 20:14:13       -0.182761        0.314541\n",
      "FIRE:   23 20:14:13       -0.192731        0.419392\n",
      "FIRE:   24 20:14:13       -0.210669        0.300459\n",
      "FIRE:   25 20:14:13       -0.219669        0.346930\n",
      "FIRE:   26 20:14:13       -0.223694        0.187074\n",
      "FIRE:   27 20:14:13       -0.227581        0.069604\n",
      "FIRE:   28 20:14:13       -0.228373        0.070119\n",
      "FIRE:   29 20:14:14       -0.228050        0.200916\n",
      "FIRE:   30 20:14:14       -0.228227        0.181135\n",
      "FIRE:   31 20:14:14       -0.228481        0.141669\n",
      "FIRE:   32 20:14:14       -0.228824        0.091059\n",
      "FIRE:   33 20:14:14       -0.229314        0.049252\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2293139398097992</span> tensor<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span> cu<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">da:0</span> <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.236</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m-0.2293139398097992\u001b[0m tensor\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m cu\u001b[1;92mda:0\u001b[0m \u001b[1m[\u001b[0m\u001b[1;36m-0.236\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "import rich\n",
    "from jmppeft.modules.relaxer import RelaxerConfig\n",
    "\n",
    "config = RelaxerConfig(\n",
    "    compute_stress=True,\n",
    "    stress_weight=0.1,\n",
    "    optimizer=\"FIRE\",\n",
    "    fmax=0.05,\n",
    "    ase_filter=\"exp\",\n",
    ")\n",
    "relaxer = Relaxer(\n",
    "    config=config,\n",
    "    model=partial(model_fn, use_y_relaxed=False),\n",
    "    collate_fn=model.collate_fn,\n",
    "    device=model.device,\n",
    ")\n",
    "rich.print(data.y_formation)\n",
    "relax_out = relaxer.relax(data)\n",
    "# rich.print(relax_out)\n",
    "\n",
    "energy = relax_out.atoms.get_total_energy()\n",
    "rich.print(energy, data.y_formation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b5a51ed99cc43229c7bd14a8ab931ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ # Steps: 20; e_form: P=-0.8377, GT=-0.8008, Δ=0.0369, MAE=0.0369\n",
      "✅ # Steps: 37; e_form: P=0.0512, GT=-0.0220, Δ=0.0732, MAE=0.0550\n",
      "✅ # Steps: 32; e_form: P=-0.6289, GT=-0.6088, Δ=0.0201, MAE=0.0434\n",
      "✅ # Steps: 75; e_form: P=-0.2388, GT=-0.1544, Δ=0.0844, MAE=0.0537\n",
      "✅ # Steps: 42; e_form: P=-0.1500, GT=-0.1154, Δ=0.0345, MAE=0.0498\n",
      "✅ # Steps: 23; e_form: P=-0.3919, GT=-0.3905, Δ=0.0014, MAE=0.0418\n",
      "✅ # Steps: 14; e_form: P=-0.2634, GT=-0.2468, Δ=0.0167, MAE=0.0382\n",
      "❌ # Steps: 15; e_form: P=-0.5672, GT=-0.4542, Δ=0.1130, MAE=0.0475\n",
      "✅ # Steps: 13; e_form: P=-1.9540, GT=-1.9089, Δ=0.0450, MAE=0.0473\n",
      "✅ # Steps: 7; e_form: P=-0.1208, GT=-0.1224, Δ=0.0016, MAE=0.0427\n",
      "✅ # Steps: 5; e_form: P=-1.9096, GT=-1.8781, Δ=0.0315, MAE=0.0417\n",
      "✅ # Steps: 5; e_form: P=-1.5727, GT=-1.6101, Δ=0.0373, MAE=0.0413\n",
      "✅ # Steps: 13; e_form: P=-1.8422, GT=-1.8180, Δ=0.0243, MAE=0.0400\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 57\u001b[0m\n\u001b[1;32m     55\u001b[0m data \u001b[38;5;241m=\u001b[39m move_data_to_device(data, model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     56\u001b[0m data\u001b[38;5;241m.\u001b[39my_prediction \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39my_formation\n\u001b[0;32m---> 57\u001b[0m relaxed_data, relax_out \u001b[38;5;241m=\u001b[39m \u001b[43mrelaxer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelax_and_return_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m e_form_true \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39my_formation\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     60\u001b[0m e_form_pred \u001b[38;5;241m=\u001b[39m relax_out\u001b[38;5;241m.\u001b[39matoms\u001b[38;5;241m.\u001b[39mget_total_energy()\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/jaxtyping/_decorator.py:449\u001b[0m, in \u001b[0;36mjaxtyped.<locals>.wrapped_fn_impl\u001b[0;34m(args, kwargs, bound, memos)\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m TypeCheckError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;66;03m# Actually call the function.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_signature\u001b[38;5;241m.\u001b[39mreturn_annotation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39mSignature\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;66;03m# Now type-check the return value. We need to include the\u001b[39;00m\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;66;03m# parameters in the type-checking here in case there are any\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;66;03m# checking of the parameters. Unfortunately there doesn't seem\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;66;03m# to be a way around that, so c'est la vie.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m     kwargs[output_name] \u001b[38;5;241m=\u001b[39m out\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/shared/repositories/jmp-peft/src/jmppeft/modules/relaxer/_mixin.py:297\u001b[0m, in \u001b[0;36mRelaxer.relax_and_return_structure\u001b[0;34m(self, graph, device, verbose)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrelax_and_return_structure\u001b[39m(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    292\u001b[0m     graph: Batch,\n\u001b[1;32m    293\u001b[0m     device: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    294\u001b[0m     verbose: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    295\u001b[0m ):\n\u001b[1;32m    296\u001b[0m     out_graph \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(graph)\n\u001b[0;32m--> 297\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     atoms \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39matoms\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;66;03m# Convert the relaxed structure to a graph\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/jaxtyping/_decorator.py:449\u001b[0m, in \u001b[0;36mjaxtyped.<locals>.wrapped_fn_impl\u001b[0;34m(args, kwargs, bound, memos)\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m TypeCheckError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;66;03m# Actually call the function.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_signature\u001b[38;5;241m.\u001b[39mreturn_annotation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39mSignature\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;66;03m# Now type-check the return value. We need to include the\u001b[39;00m\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;66;03m# parameters in the type-checking here in case there are any\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;66;03m# checking of the parameters. Unfortunately there doesn't seem\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;66;03m# to be a way around that, so c'est la vie.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m     kwargs[output_name] \u001b[38;5;241m=\u001b[39m out\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/shared/repositories/jmp-peft/src/jmppeft/modules/relaxer/_mixin.py:278\u001b[0m, in \u001b[0;36mRelaxer.relax\u001b[0;34m(self, graph, verbose)\u001b[0m\n\u001b[1;32m    267\u001b[0m atoms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_to_atoms(graph)\n\u001b[1;32m    269\u001b[0m relaxer \u001b[38;5;241m=\u001b[39m _Relaxer(\n\u001b[1;32m    270\u001b[0m     potential\u001b[38;5;241m=\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_potential, initial_graph\u001b[38;5;241m=\u001b[39mgraph),\n\u001b[1;32m    271\u001b[0m     graph_converter\u001b[38;5;241m=\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_atoms_to_graph, initial_graph\u001b[38;5;241m=\u001b[39mgraph),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    276\u001b[0m     ase_filter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mase_filter,\n\u001b[1;32m    277\u001b[0m )\n\u001b[0;32m--> 278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrelaxer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelax\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43matoms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraj_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraj_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabsolute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraj_file\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/jaxtyping/_decorator.py:449\u001b[0m, in \u001b[0;36mjaxtyped.<locals>.wrapped_fn_impl\u001b[0;34m(args, kwargs, bound, memos)\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m TypeCheckError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;66;03m# Actually call the function.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_signature\u001b[38;5;241m.\u001b[39mreturn_annotation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39mSignature\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;66;03m# Now type-check the return value. We need to include the\u001b[39;00m\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;66;03m# parameters in the type-checking here in case there are any\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;66;03m# checking of the parameters. Unfortunately there doesn't seem\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;66;03m# to be a way around that, so c'est la vie.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m     kwargs[output_name] \u001b[38;5;241m=\u001b[39m out\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/shared/repositories/jmp-peft/src/jmppeft/modules/relaxer/_relaxer.py:332\u001b[0m, in \u001b[0;36mRelaxer.relax\u001b[0;34m(self, atoms, fmax, steps, traj_file, interval, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    330\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_cls(atoms, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    331\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mattach(obs, interval\u001b[38;5;241m=\u001b[39minterval)\n\u001b[0;32m--> 332\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m     obs()\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m traj_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/ase/optimize/optimize.py:430\u001b[0m, in \u001b[0;36mOptimizer.run\u001b[0;34m(self, fmax, steps)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run optimizer.\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;124;03m    True if the forces on atoms are converged.\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmax \u001b[38;5;241m=\u001b[39m fmax\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDynamics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/ase/optimize/optimize.py:275\u001b[0m, in \u001b[0;36mDynamics.run\u001b[0;34m(self, steps)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, steps\u001b[38;5;241m=\u001b[39mDEFAULT_MAX_STEPS):\n\u001b[1;32m    258\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run dynamics algorithm.\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \n\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03m    This method will return when the forces on all individual\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;124;03m        True if the forces on atoms are converged.\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 275\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconverged\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDynamics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mirun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mpass\u001b[39;49;00m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m converged\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/ase/optimize/optimize.py:254\u001b[0m, in \u001b[0;36mDynamics.irun\u001b[0;34m(self, steps)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_observers()\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# check convergence\u001b[39;00m\n\u001b[0;32m--> 254\u001b[0m is_converged \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverged\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m is_converged\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/ase/optimize/optimize.py:435\u001b[0m, in \u001b[0;36mOptimizer.converged\u001b[0;34m(self, forces)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Did the optimization converge?\"\"\"\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m forces \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 435\u001b[0m     forces \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_forces\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizable\u001b[38;5;241m.\u001b[39mconverged(forces, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmax)\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/ase/filters.py:29\u001b[0m, in \u001b[0;36mOptimizableFilter.get_forces\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_forces\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilterobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_forces\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/ase/filters.py:821\u001b[0m, in \u001b[0;36mExpCellFilter.get_forces\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m virial \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mvolume \u001b[38;5;241m*\u001b[39m (voigt_6_to_full_3x3_stress(stress) \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    818\u001b[0m                     np\u001b[38;5;241m.\u001b[39mdiag([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscalar_pressure] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m    820\u001b[0m cur_deform_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeform_grad()\n\u001b[0;32m--> 821\u001b[0m cur_deform_grad_log \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur_deform_grad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhydrostatic_strain:\n\u001b[1;32m    824\u001b[0m     vtr \u001b[38;5;241m=\u001b[39m virial\u001b[38;5;241m.\u001b[39mtrace()\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/scipy/linalg/_matfuncs.py:200\u001b[0m, in \u001b[0;36mlogm\u001b[0;34m(A, disp)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# Avoid circular import ... this is OK, right?\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_matfuncs_inv_ssq\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m F \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_matfuncs_inv_ssq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_logm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m F \u001b[38;5;241m=\u001b[39m _maybe_real(A, F)\n\u001b[1;32m    202\u001b[0m errtol \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\u001b[38;5;241m*\u001b[39meps\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/scipy/linalg/_matfuncs_inv_ssq.py:880\u001b[0m, in \u001b[0;36m_logm\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m    878\u001b[0m     T, Z \u001b[38;5;241m=\u001b[39m schur(A, output\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomplex\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    879\u001b[0m T \u001b[38;5;241m=\u001b[39m _logm_force_nonsingular_triangular_matrix(T, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 880\u001b[0m U \u001b[38;5;241m=\u001b[39m \u001b[43m_logm_triu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m ZH \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconjugate(Z)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Z\u001b[38;5;241m.\u001b[39mdot(U)\u001b[38;5;241m.\u001b[39mdot(ZH)\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/scipy/linalg/_matfuncs_inv_ssq.py:777\u001b[0m, in \u001b[0;36m_logm_triu\u001b[0;34m(T)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;66;03m# Define bounds given in Table (2.1).\u001b[39;00m\n\u001b[1;32m    771\u001b[0m theta \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    772\u001b[0m         \u001b[38;5;241m1.59e-5\u001b[39m, \u001b[38;5;241m2.31e-3\u001b[39m, \u001b[38;5;241m1.94e-2\u001b[39m, \u001b[38;5;241m6.21e-2\u001b[39m,\n\u001b[1;32m    773\u001b[0m         \u001b[38;5;241m1.28e-1\u001b[39m, \u001b[38;5;241m2.06e-1\u001b[39m, \u001b[38;5;241m2.88e-1\u001b[39m, \u001b[38;5;241m3.67e-1\u001b[39m,\n\u001b[1;32m    774\u001b[0m         \u001b[38;5;241m4.39e-1\u001b[39m, \u001b[38;5;241m5.03e-1\u001b[39m, \u001b[38;5;241m5.60e-1\u001b[39m, \u001b[38;5;241m6.09e-1\u001b[39m,\n\u001b[1;32m    775\u001b[0m         \u001b[38;5;241m6.52e-1\u001b[39m, \u001b[38;5;241m6.89e-1\u001b[39m, \u001b[38;5;241m7.21e-1\u001b[39m, \u001b[38;5;241m7.49e-1\u001b[39m)\n\u001b[0;32m--> 777\u001b[0m R, s, m \u001b[38;5;241m=\u001b[39m \u001b[43m_inverse_squaring_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mT0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;66;03m# Evaluate U = 2**s r_m(T - I) using the partial fraction expansion (1.1).\u001b[39;00m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;66;03m# This requires the nodes and weights\u001b[39;00m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;66;03m# corresponding to degree-m Gauss-Legendre quadrature.\u001b[39;00m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;66;03m# These quadrature arrays need to be transformed from the [-1, 1] interval\u001b[39;00m\n\u001b[1;32m    783\u001b[0m \u001b[38;5;66;03m# to the [0, 1] interval.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m nodes, weights \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39mspecial\u001b[38;5;241m.\u001b[39mp_roots(m)\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/scipy/linalg/_matfuncs_inv_ssq.py:385\u001b[0m, in \u001b[0;36m_inverse_squaring_helper\u001b[0;34m(T0, theta)\u001b[0m\n\u001b[1;32m    383\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    384\u001b[0m d2 \u001b[38;5;241m=\u001b[39m _onenormest_m1_power(T, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 385\u001b[0m d3 \u001b[38;5;241m=\u001b[39m \u001b[43m_onenormest_m1_power\u001b[49m\u001b[43m(\u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    386\u001b[0m a2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(d2, d3)\n\u001b[1;32m    387\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/scipy/linalg/_matfuncs_inv_ssq.py:111\u001b[0m, in \u001b[0;36m_onenormest_m1_power\u001b[0;34m(A, p, t, itmax, compute_v, compute_w)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_onenormest_m1_power\u001b[39m(A, p,\n\u001b[1;32m     75\u001b[0m         t\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, itmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, compute_v\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, compute_w\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03m    Efficiently estimate the 1-norm of (A - I)^p.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    109\u001b[0m \n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43monenormest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MatrixM1PowerOperator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m            \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mitmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_v\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_w\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_w\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/scipy/sparse/linalg/_onenormest.py:107\u001b[0m, in \u001b[0;36monenormest\u001b[0;34m(A, t, itmax, compute_v, compute_w)\u001b[0m\n\u001b[1;32m    105\u001b[0m     est \u001b[38;5;241m=\u001b[39m col_abs_sums[argmax_j]\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 107\u001b[0m     est, v, w, nmults, nresamples \u001b[38;5;241m=\u001b[39m \u001b[43m_onenormest_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitmax\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# Report the norm estimate along with some certificates of the estimate.\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compute_v \u001b[38;5;129;01mor\u001b[39;00m compute_w:\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/scipy/sparse/linalg/_onenormest.py:431\u001b[0m, in \u001b[0;36m_onenormest_core\u001b[0;34m(A, AT, t, itmax)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;66;03m# \"Ensure that no column of S is parallel to another column of S\u001b[39;00m\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;66;03m# or to a column of S_old by replacing columns of S by rand{-1,1}.\"\u001b[39;00m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(t):\n\u001b[0;32m--> 431\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43mcolumn_needs_resampling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mS_old\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    432\u001b[0m             resample_column(i, S)\n\u001b[1;32m    433\u001b[0m             nresamples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/nima/miniforge3/envs/jmp-peft/lib/python3.11/site-packages/scipy/sparse/linalg/_onenormest.py:199\u001b[0m, in \u001b[0;36mcolumn_needs_resampling\u001b[0;34m(i, X, Y)\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcolumn_needs_resampling\u001b[39m(i, X, Y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# column i of X needs resampling if either\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# it is parallel to a previous column of X or\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m# it is parallel to a column of Y\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     n, t \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    204\u001b[0m     v \u001b[38;5;241m=\u001b[39m X[:, i]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from typing import TypedDict, cast\n",
    "\n",
    "import numpy as np\n",
    "from jmppeft.modules.relaxer._relaxer import RelaxationOutput\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.data import Batch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "use_y_relaxed = False\n",
    "\n",
    "config = RelaxerConfig(\n",
    "    compute_stress=True,\n",
    "    stress_weight=0.1,\n",
    "    optimizer=\"FIRE\",\n",
    "    # fmax=0.01,\n",
    "    # ase_filter=\"frechet\",\n",
    "    fmax=0.05,\n",
    "    ase_filter=\"exp\",\n",
    ")\n",
    "relaxer = Relaxer(\n",
    "    config=config,\n",
    "    model=partial(model_fn, use_y_relaxed=use_y_relaxed),\n",
    "    collate_fn=model.collate_fn,\n",
    "    device=model.device,\n",
    ")\n",
    "\n",
    "dl = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,\n",
    "    collate_fn=model.collate_fn,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "preds_targets = defaultdict[str, list[tuple[float, float]]](lambda: [])\n",
    "mae_error = 0.0\n",
    "mae_count = 0\n",
    "\n",
    "\n",
    "class ProblematicSample(TypedDict):\n",
    "    error: float\n",
    "    initial_data: Batch\n",
    "    relaxed_data: Batch\n",
    "    relax_out: RelaxationOutput\n",
    "\n",
    "\n",
    "problematic_samples: list[ProblematicSample] = []\n",
    "ae_threshold = 0.1\n",
    "\n",
    "for data in tqdm(dl, total=len(dl)):\n",
    "    data = cast(Batch, data)\n",
    "    data = move_data_to_device(data, model.device)\n",
    "    data.y_prediction = data.y_formation\n",
    "    relaxed_data, relax_out = relaxer.relax_and_return_structure(data, verbose=False)\n",
    "\n",
    "    e_form_true = data.y_formation.item()\n",
    "    e_form_pred = relax_out.atoms.get_total_energy()\n",
    "    preds_targets[\"e_form\"].append((e_form_pred, e_form_true))\n",
    "\n",
    "    e_above_hull_true = data.y_above_hull.item()\n",
    "    e_above_hull_pred = e_above_hull_true + (e_form_pred - e_form_true)\n",
    "    preds_targets[\"e_above_hull\"].append((e_above_hull_pred, e_above_hull_true))\n",
    "\n",
    "    mae_error += abs(e_form_pred - e_form_true)\n",
    "    mae_count += 1\n",
    "    mae_running = mae_error / mae_count\n",
    "\n",
    "    nsteps = len(relax_out.trajectory.frames)\n",
    "\n",
    "    error = abs(e_form_pred - e_form_true)\n",
    "    prefix = \"✅\"\n",
    "    if error > ae_threshold:\n",
    "        problematic_samples.append(\n",
    "            {\n",
    "                \"error\": error,\n",
    "                \"initial_data\": move_data_to_device(data, \"cpu\"),\n",
    "                \"relaxed_data\": move_data_to_device(relaxed_data, \"cpu\"),\n",
    "                \"relax_out\": move_data_to_device(relax_out, \"cpu\"),\n",
    "            }\n",
    "        )\n",
    "        prefix = \"❌\"\n",
    "\n",
    "    print(\n",
    "        f\"{prefix} # Steps: {nsteps}; e_form: P={e_form_pred:.4f}, GT={e_form_true:.4f}, Δ={abs(e_form_pred - e_form_true):.4f}, MAE={mae_running:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3f3e4384a5472e96205497cda28584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(NGLWidget(), VBox(children=(Dropdown(description='Show', options=('All', 'Rh', 'Dy', 'H'), valu…"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "\n",
    "def compute_relaxed(\n",
    "    sample: ProblematicSample,\n",
    "):\n",
    "    relax_out = sample[\"relax_out\"]\n",
    "\n",
    "    initial_data = move_data_to_device(\n",
    "        copy.deepcopy(sample[\"initial_data\"]), model.device\n",
    "    )\n",
    "    data = move_data_to_device(copy.deepcopy(sample[\"initial_data\"]), model.device)\n",
    "\n",
    "    for f in tqdm(relax_out.trajectory.frames):\n",
    "        data.pos = f.pos.type_as(data.pos).reshape_as(data.pos).to(data.pos.device)\n",
    "        data.cell = f.cell.type_as(data.cell).reshape_as(data.cell).to(data.cell.device)\n",
    "\n",
    "        out = model_fn(data, initial_data, use_y_relaxed=True)\n",
    "        yield out[\"energy\"].item()\n",
    "\n",
    "\n",
    "def plot_energy_vs_steps(\n",
    "    sample: ProblematicSample,\n",
    "    ax: plt.Axes | None = None,\n",
    "):\n",
    "    initial_data = sample[\"initial_data\"]\n",
    "    relax_out = sample[\"relax_out\"]\n",
    "\n",
    "    e_form_true = initial_data.y_formation.item()\n",
    "    e_form_pred = [f.energy.item() for f in relax_out.trajectory.frames]\n",
    "    e_form_pred_relaxed = None\n",
    "    if True:\n",
    "        e_form_pred_relaxed = list(compute_relaxed(sample))\n",
    "\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "    ax.plot(e_form_pred, label=\"Predicted\")\n",
    "    if e_form_pred_relaxed:\n",
    "        ax.plot(e_form_pred_relaxed, label=\"Predicted (y_relaxed)\")\n",
    "    ax.axhline(y=e_form_true, color=\"r\", linestyle=\"--\", label=\"True\")\n",
    "    ax.set_xlabel(\"Step\")\n",
    "    ax.set_ylabel(\"Formation Energy\")\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "def plot_initial_structure(sample: ProblematicSample):\n",
    "    import ase\n",
    "\n",
    "    initial_data = sample[\"initial_data\"]\n",
    "    atoms = ase.Atoms(\n",
    "        numbers=initial_data.atomic_numbers.cpu().numpy(),\n",
    "        positions=initial_data.pos.cpu().numpy(),\n",
    "        cell=initial_data.cell.cpu().squeeze(0).numpy(),\n",
    "        pbc=[True, True, True],\n",
    "    )\n",
    "\n",
    "    import ase.visualize\n",
    "\n",
    "    return ase.visualize.view(atoms, viewer=\"ngl\")\n",
    "\n",
    "\n",
    "# plot_energy_vs_steps(problematic_samples[0])\n",
    "plot_initial_structure(problematic_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lustre/orion/mat265/world-shared/nimashoghi/projectdata/miniforge3/envs/rocm57/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7056, 7056])\n",
      "tensor([7056, 7056], device='cuda:0')\n",
      "tensor([ 7056, 14112], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([7056, 7056], dtype=torch.long)\n",
    "print(x)\n",
    "x = x.cuda()\n",
    "print(x)\n",
    "x = x.cumsum(0)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monkey_patch_torch_scatter():\n",
    "    import torch\n",
    "    import torch_scatter\n",
    "\n",
    "    def segment_coo(\n",
    "        src: torch.Tensor,\n",
    "        index: torch.Tensor,\n",
    "        out: torch.Tensor | None = None,\n",
    "        dim_size: int | None = None,\n",
    "        reduce: str = \"sum\",\n",
    "    ):\n",
    "        # Dim should be the first (and only) non-broadcastable dimension in index.\n",
    "        dims_to_squeeze: list[int] = []\n",
    "        dim: int = -1\n",
    "        for dim_idx in range(index.dim()):\n",
    "            if index.size(dim_idx) == 1:\n",
    "                dims_to_squeeze.append(dim)\n",
    "                continue\n",
    "\n",
    "            if dim != -1:\n",
    "                raise ValueError(\n",
    "                    \"Found multiple non-broadcastable dimensions in index.\"\n",
    "                )\n",
    "            dim = dim_idx\n",
    "\n",
    "        index = index.squeeze(dims_to_squeeze)\n",
    "        return torch_scatter.scatter(src, index, dim, out, dim_size, reduce)\n",
    "\n",
    "    torch_scatter.segment_coo = segment_coo\n",
    "\n",
    "    print(\"Monkey-patched torch_scatter.segment_coo\")\n",
    "\n",
    "\n",
    "# monkey_patch_torch_scatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 64])\n"
     ]
    }
   ],
   "source": [
    "from torch_scatter import segment_csr\n",
    "\n",
    "src = torch.randn(10, 6, 64).cuda()\n",
    "indptr = torch.tensor([0, 2, 5, 6]).cuda()\n",
    "indptr = indptr.view(1, -1)  # Broadcasting in the first and last dim.\n",
    "\n",
    "out = segment_csr(src, indptr, reduce=\"sum\")\n",
    "\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unknown layout",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m])\u001b[38;5;241m.\u001b[39mcuda()\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m      5\u001b[0m index \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Broadcasting in the first and last dim.\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43msegment_coo\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(out\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[0;32m/lustre/orion/mat265/world-shared/nimashoghi/projectdata/miniforge3/envs/rocm57/lib/python3.11/site-packages/torch_scatter-2.1.2-py3.11-linux-x86_64.egg/torch_scatter/segment_coo.py:124\u001b[0m, in \u001b[0;36msegment_coo\u001b[0;34m(src, index, out, dim_size, reduce)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m|\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m    torch.Size([10, 3, 64])\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msegment_sum_coo\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m segment_mean_coo(src, index, out, dim_size)\n",
      "File \u001b[0;32m/lustre/orion/mat265/world-shared/nimashoghi/projectdata/miniforge3/envs/rocm57/lib/python3.11/site-packages/torch_scatter-2.1.2-py3.11-linux-x86_64.egg/torch_scatter/segment_coo.py:9\u001b[0m, in \u001b[0;36msegment_sum_coo\u001b[0;34m(src, index, out, dim_size)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msegment_sum_coo\u001b[39m(src: torch\u001b[38;5;241m.\u001b[39mTensor, index: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m      7\u001b[0m                     out: Optional[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m      8\u001b[0m                     dim_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch_scatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msegment_sum_coo\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/lustre/orion/mat265/world-shared/nimashoghi/projectdata/miniforge3/envs/rocm57/lib/python3.11/site-packages/torch/_ops.py:755\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    751\u001b[0m     \u001b[38;5;66;03m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;66;03m# is still callable from JIT\u001b[39;00m\n\u001b[1;32m    753\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    754\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unknown layout"
     ]
    }
   ],
   "source": [
    "from torch_scatter import segment_coo\n",
    "\n",
    "src = torch.randn(10, 6, 64).cuda().contiguous()\n",
    "index = torch.tensor([0, 0, 1, 1, 1, 2]).cuda().contiguous()\n",
    "index = index.view(1, -1)  # Broadcasting in the first and last dim.\n",
    "\n",
    "out = segment_coo(src, index, reduce=\"sum\")\n",
    "\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 64])\n",
      "torch.Size([10, 3, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_113800/1652682880.py:21: FutureWarning: `torch.testing.assert_allclose()` is deprecated since 1.12 and will be removed in a future release. Please use `torch.testing.assert_close()` instead. You can find detailed upgrade instructions in https://github.com/pytorch/pytorch/issues/61844.\n",
      "  torch.testing.assert_allclose(out_scatter, out_coo)\n",
      "/tmp/ipykernel_113800/1652682880.py:22: FutureWarning: `torch.testing.assert_allclose()` is deprecated since 1.12 and will be removed in a future release. Please use `torch.testing.assert_close()` instead. You can find detailed upgrade instructions in https://github.com/pytorch/pytorch/issues/61844.\n",
      "  torch.testing.assert_allclose(out_scatter, out_csr)\n"
     ]
    }
   ],
   "source": [
    "# Torch Scatter Tests\n",
    "from torch_scatter import scatter_add, segment_coo, segment_csr\n",
    "\n",
    "src = torch.randn(10, 6, 64).cuda()\n",
    "\n",
    "index = torch.tensor([0, 0, 1, 1, 1, 2]).cuda()\n",
    "out_scatter = scatter_add(src, index, dim=1)\n",
    "print(out_scatter.shape)\n",
    "\n",
    "index = torch.tensor([0, 0, 1, 1, 1, 2]).cuda()\n",
    "index = index.view(1, -1)  # Broadcasting in the first and last dim.\n",
    "\n",
    "out_coo = segment_coo(src, index, reduce=\"sum\")\n",
    "print(out_coo.shape)\n",
    "\n",
    "indptr = torch.tensor([0, 2, 5, 6]).cuda()\n",
    "indptr = indptr.view(1, -1)  # Broadcasting in the first and last dim.\n",
    "\n",
    "out_csr = segment_csr(src, indptr, reduce=\"sum\")\n",
    "\n",
    "torch.testing.assert_allclose(out_scatter, out_coo)\n",
    "torch.testing.assert_allclose(out_scatter, out_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_sparse import coalesce\n",
    "\n",
    "index = torch.tensor([[1, 0, 1, 0, 2, 1], [0, 1, 1, 1, 0, 0]]).cuda()\n",
    "value = torch.tensor([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]]).cuda()\n",
    "\n",
    "index, value = coalesce(index, value, m=3, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_sparse import transpose\n",
    "\n",
    "index = torch.tensor([[1, 0, 1, 0, 2, 1], [0, 1, 1, 1, 0, 0]]).cuda()\n",
    "value = torch.tensor([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]]).cuda()\n",
    "\n",
    "index, value = transpose(index, value, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_sparse import spmm\n",
    "\n",
    "index = torch.tensor([[0, 0, 1, 2, 2], [0, 2, 1, 0, 1]]).cuda()\n",
    "value = torch.tensor([1, 2, 4, 1, 3]).cuda()\n",
    "matrix = torch.tensor([[1, 4], [2, 5], [3, 6]]).cuda()\n",
    "\n",
    "out = spmm(index, value, 3, 3, matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch_sparse import spspmm\n",
    "\n",
    "# indexA = torch.tensor([[0, 0, 1, 2, 2], [1, 2, 0, 0, 1]]).cudA()\n",
    "# valueA = torch.tensor([1, 2, 3, 4, 5]).cudA()\n",
    "\n",
    "# indexB = torch.tensor([[0, 2], [1, 0]]).cudA()\n",
    "# valueB = torch.tensor([2, 4]).cudA()\n",
    "\n",
    "# indexC, valueC = spspmm(indexA, valueA, indexB, valueB, 3, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10]) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "from torch_sparse import SparseTensor\n",
    "\n",
    "row = torch.tensor([0, 0, 1, 1, 2, 2, 2, 3, 3, 4]).cuda()\n",
    "col = torch.tensor([1, 2, 0, 2, 0, 1, 3, 2, 4, 3]).cuda()\n",
    "num_edges = row.size(0)\n",
    "num_nodes = int(max(row.max().item(), col.max().item())) + 1\n",
    "adj = SparseTensor(\n",
    "    row=row,\n",
    "    col=col,\n",
    "    value=torch.arange(num_edges).cuda(),\n",
    "    sparse_sizes=(num_nodes, num_nodes),\n",
    ")\n",
    "\n",
    "in_ = adj.storage.value()\n",
    "out_ = adj.storage.row()\n",
    "\n",
    "print(in_.shape, out_.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

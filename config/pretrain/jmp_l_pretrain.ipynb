{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='nwbzqfcs' name=None project=None tags=[] notes=[] debug=False environment=EnvironmentConfig(cwd=None, python_executable=None, python_path=None, python_version=None, config=None, model=None, data=None, slurm=None, log_dir=None, seed=None, seed_workers=None, sweep_id=None, sweep_config=None) trainer=TrainerConfig(python_logging=PythonLogging(log_level=None, rich=True, rich_tracebacks=True, lovely_tensors=True, lovely_numpy=False), logging=LoggingConfig(enabled=True, log_lr=True, log_epoch=True, wandb=WandbLoggingConfig(enabled=True, log_model=False, watch=WandbWatchConfig(enabled=True, log=None, log_graph=True, log_freq=100)), csv=CSVLoggingConfig(enabled=True), tensorboard=TensorboardLoggingConfig(enabled=False)), optimizer=OptimizerConfig(grad_finite_checks=False, grad_none_checks=False, log_grad_norm=True, log_grad_norm_per_param=False, log_param_norm=False, log_param_norm_per_param=False, gradient_clipping=GradientClippingConfig(enabled=True, value=1.0, algorithm='norm'), gradient_skipping=None), seed=0, seed_workers=False, default_ckpt_path=None, auto_wrap_trainer=True, auto_set_default_root_dir=True, auto_set_loggers=True, checkpoint_last_by_default=True, on_exception_checkpoint=True, auto_add_trainer_finalizer=True, enable_logger_validation=True, supports_skip_batch_exception=False, supports_shared_parameters=True, supports_parameter_hooks=False, log_batch_info_on_error=False, reduce_lr_on_plateau_sanity_checks='error', additional_trainer_kwargs={}, additional_env_vars={}, set_nccl_optimal_params=False, set_float32_matmul_precision='medium', accelerator='auto', strategy='auto', devices='auto', num_nodes='auto', precision='16-mixed', logger=None, fast_dev_run=False, max_epochs=None, min_epochs=None, max_steps=-1, min_steps=None, max_time=None, limit_train_batches=None, limit_val_batches=None, limit_test_batches=None, limit_predict_batches=None, overfit_batches=0.0, val_check_interval=None, check_val_every_n_epoch=1, num_sanity_val_steps=None, log_every_n_steps=50, enable_checkpointing=None, enable_progress_bar=None, enable_model_summary=None, accumulate_grad_batches=1, deterministic=None, benchmark=None, inference_mode=True, use_distributed_sampler=False, profiler=None, detect_anomaly=False, barebones=False, plugins=None, sync_batchnorm=False, reload_dataloaders_every_n_epochs=0, default_root_dir=None) runner=RunnerConfig(auto_call_trainer_init_from_runner=True, save_output=None) meta={} optimizer=AdamWConfig(name='adamw', lr=0.0003, weight_decay=0.1, betas=(0.9, 0.95), eps=1e-08, amsgrad=False) lr_scheduler=LinearWarmupCosineAnnealingSchedulerConfig(name='linear_warmup_cosine_annealing', warmup_steps=2000, max_steps=None, max_epochs=2, warmup_start_lr_factor=0.2, min_lr_factor=0.1, last_step=-1) activation='scaled_silu' dropout=None edge_dropout=0.1 embedding=EmbeddingConfig(num_elements=120, embedding_size=256) backbone=BackboneConfig(num_targets=1, num_spherical=7, num_radial=128, num_blocks=4, emb_size_atom=256, emb_size_edge=512, emb_size_trip_in=64, emb_size_trip_out=64, emb_size_quad_in=32, emb_size_quad_out=32, emb_size_aint_in=64, emb_size_aint_out=64, emb_size_rbf=16, emb_size_cbf=16, emb_size_sbf=32, num_before_skip=2, num_after_skip=2, num_concat=1, num_atom=3, num_output_afteratom=3, num_atom_emb_layers=2, num_global_out_layers=2, regress_forces=True, regress_energy=True, direct_forces=True, use_pbc=True, scale_backprop_forces=False, rbf={'name': 'gaussian'}, rbf_spherical=None, envelope={'name': 'polynomial', 'exponent': 5}, cbf={'name': 'spherical_harmonics'}, sbf={'name': 'legendre_outer'}, extensive=True, forces_coupled=False, activation='scaled_silu', quad_interaction=True, atom_edge_interaction=True, edge_atom_interaction=True, atom_interaction=True, scale_basis=False, qint_tags=[1, 2], num_elements=120, otf_graph=False, scale_file=None, absolute_rbf_cutoff=12.0, learnable_rbf=False, learnable_rbf_stds=False, unique_basis_per_layer=False, dropout=None, edge_dropout=0.1) output=OutputConfig(num_mlps=5, output_init='HeOrthogonal') batch_size=4 eval_batch_size=None num_workers=0 pin_memory=True shuffle_train=True shuffle_val=False log_task_losses=True log_task_steps_and_epochs=True tasks=[TaskConfig(name='oc20', train_dataset=PretrainDatasetConfig(sample_n=None, atom_ref=None, src=PosixPath('/datasets/s2ef/2M/train'), metadata_path=PosixPath('/datasets/s2ef/2M/train_metadata.npz'), total_energy=None, oc20_ref=None, lin_ref=None), val_dataset=PretrainDatasetConfig(sample_n=None, atom_ref=None, src=PosixPath('/datasets/s2ef/all/val_id'), metadata_path=PosixPath('/datasets/s2ef/all/val_id_metadata.npz'), total_energy=None, oc20_ref=None, lin_ref=None), node_energy_reduction='sum', additional_units=[], energy_loss_scale=1.0, force_loss_scale=73.0, normalization={'y': NormalizationConfig(mean=0.0, std=24.901469505465872), 'force': NormalizationConfig(mean=0.0, std=0.5111534595489502)}), TaskConfig(name='oc22', train_dataset=PretrainDatasetConfig(sample_n=None, atom_ref=None, src=PosixPath('/shared/pre-training-datasets/oc22/s2ef-total/train'), metadata_path=PosixPath('/shared/pre-training-datasets/oc22/s2ef-total/train/metadata.npz'), total_energy=None, oc20_ref=None, lin_ref=None), val_dataset=PretrainDatasetConfig(sample_n=None, atom_ref=None, src=PosixPath('/shared/pre-training-datasets/oc22/s2ef-total/val_id'), metadata_path=PosixPath('/shared/pre-training-datasets/oc22/s2ef-total/val_id/metadata.npz'), total_energy=None, oc20_ref=None, lin_ref=None), node_energy_reduction='sum', additional_units=[], energy_loss_scale=1.0, force_loss_scale=80.0, normalization={'y': NormalizationConfig(mean=0.0, std=25.229595396538468), 'force': NormalizationConfig(mean=0.0, std=0.25678861141204834)}), TaskConfig(name='ani1x', train_dataset=PretrainDatasetConfig(sample_n=None, atom_ref=None, src=PosixPath('/shared/pre-training-datasets/ani1x/train'), metadata_path=PosixPath('/shared/pre-training-datasets/ani1x/train/metadata.npz'), total_energy=None, oc20_ref=None, lin_ref=None), val_dataset=PretrainDatasetConfig(sample_n=None, atom_ref=None, src=PosixPath('/shared/pre-training-datasets/ani1x/val'), metadata_path=PosixPath('/shared/pre-training-datasets/ani1x/val/metadata.npz'), total_energy=None, oc20_ref=None, lin_ref=None), node_energy_reduction='sum', additional_units=[], energy_loss_scale=1.0, force_loss_scale=15.0, normalization={'y': NormalizationConfig(mean=0.0, std=2.8700712783472118), 'force': NormalizationConfig(mean=0.0, std=2.131422996520996)}), TaskConfig(name='transition1x', train_dataset=PretrainDatasetConfig(sample_n=None, atom_ref=None, src=PosixPath('/shared/pre-training-datasets/trans1x/train'), metadata_path=PosixPath('/shared/pre-training-datasets/trans1x/train/metadata.npz'), total_energy=None, oc20_ref=None, lin_ref=None), val_dataset=PretrainDatasetConfig(sample_n=None, atom_ref=None, src=PosixPath('/shared/pre-training-datasets/trans1x/val'), metadata_path=PosixPath('/shared/pre-training-datasets/trans1x/val/metadata.npz'), total_energy=None, oc20_ref=None, lin_ref=None), node_energy_reduction='sum', additional_units=[], energy_loss_scale=1.0, force_loss_scale=14.0, normalization={'y': NormalizationConfig(mean=0.0, std=1.787466168382901), 'force': NormalizationConfig(mean=0.0, std=0.3591422140598297)})] mt_dataset=MTDatasetConfig(balanced=None, strict=True, taskify_keys_graph=['y', 'y_scale', 'force_scale'], taskify_keys_node=['force'], taskify_use_onehot=True, sample_type='temperature', sample_temperature=2.0) exclude_keys=['id', 'fid', 'cell_offsets', 'edge_index', 'absolute_idx', 'target_pos', 'ref_energy', 'pbc', 'oc22', 'name'] train_on_free_atoms_only=False eval_on_free_atoms_only=True energy_loss_reduction='mean' force_loss_reduction='mean' structurewise_loss_reduction=True ema=EMAConfig(decay=0.99, validate_original_weights=False, every_n_steps=1, cpu_offload=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/repositories/fm/src/ll/model/config.py:709: IdSeedWarning: BaseConfig._rng is None. The generated IDs will not be reproducible. To fix this, call BaseConfig.set_seed(...) before generating any IDs.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from jmpfm.tasks.pretrain import PretrainConfig, PretrainModel\n",
    "from jmpfm.tasks.pretrain.module import (\n",
    "    NormalizationConfig,\n",
    "    PretrainDatasetConfig,\n",
    "    TaskConfig,\n",
    ")\n",
    "from jmpfm.configs.pretrain import jmp_l_pt_config_builder\n",
    "\n",
    "\n",
    "# Let's make the config\n",
    "def jmp_l_config():\n",
    "    with jmp_l_pt_config_builder() as (builder, config):\n",
    "        # Set data config\n",
    "        config.batch_size = 4\n",
    "        config.num_workers = 0\n",
    "\n",
    "        # Set the tasks\n",
    "        config.tasks = [\n",
    "            TaskConfig(\n",
    "                name=\"oc20\",\n",
    "                train_dataset=PretrainDatasetConfig(\n",
    "                    src=Path(\"/datasets/s2ef/2M/train/\"),\n",
    "                    metadata_path=Path(\"/datasets/s2ef/2M/train_metadata.npz\"),\n",
    "                ),\n",
    "                val_dataset=PretrainDatasetConfig(\n",
    "                    src=Path(\"/datasets/s2ef/all/val_id/\"),\n",
    "                    metadata_path=Path(\"/datasets/s2ef/all/val_id_metadata.npz\"),\n",
    "                ),\n",
    "                energy_loss_scale=1.0,\n",
    "                force_loss_scale=73.0,\n",
    "                normalization={\n",
    "                    \"y\": NormalizationConfig(mean=0.0, std=24.901469505465872),\n",
    "                    \"force\": NormalizationConfig(mean=0.0, std=0.5111534595489502),\n",
    "                },\n",
    "            ),\n",
    "            TaskConfig(\n",
    "                name=\"oc22\",\n",
    "                train_dataset=PretrainDatasetConfig(\n",
    "                    src=Path(\"/shared/pre-training-datasets/oc22/s2ef-total/train/\"),\n",
    "                ),\n",
    "                val_dataset=PretrainDatasetConfig(\n",
    "                    src=Path(\"/shared/pre-training-datasets/oc22/s2ef-total/val_id/\"),\n",
    "                ),\n",
    "                energy_loss_scale=1.0,\n",
    "                force_loss_scale=80.0,\n",
    "                normalization={\n",
    "                    \"y\": NormalizationConfig(mean=0.0, std=25.229595396538468),\n",
    "                    \"force\": NormalizationConfig(mean=0.0, std=0.25678861141204834),\n",
    "                },\n",
    "            ),\n",
    "            TaskConfig(\n",
    "                name=\"ani1x\",\n",
    "                train_dataset=PretrainDatasetConfig(\n",
    "                    src=Path(\"/shared/pre-training-datasets/ani1x/train/\"),\n",
    "                ),\n",
    "                val_dataset=PretrainDatasetConfig(\n",
    "                    src=Path(\"/shared/pre-training-datasets/ani1x/val/\"),\n",
    "                ),\n",
    "                energy_loss_scale=1.0,\n",
    "                force_loss_scale=15.0,\n",
    "                normalization={\n",
    "                    \"y\": NormalizationConfig(mean=0.0, std=2.8700712783472118),\n",
    "                    \"force\": NormalizationConfig(mean=0.0, std=2.131422996520996),\n",
    "                },\n",
    "            ),\n",
    "            TaskConfig(\n",
    "                name=\"transition1x\",\n",
    "                train_dataset=PretrainDatasetConfig(\n",
    "                    src=Path(\"/shared/pre-training-datasets/trans1x/train/\"),\n",
    "                ),\n",
    "                val_dataset=PretrainDatasetConfig(\n",
    "                    src=Path(\"/shared/pre-training-datasets/trans1x/val/\"),\n",
    "                ),\n",
    "                energy_loss_scale=1.0,\n",
    "                force_loss_scale=14.0,\n",
    "                normalization={\n",
    "                    \"y\": NormalizationConfig(mean=0.0, std=1.787466168382901),\n",
    "                    \"force\": NormalizationConfig(mean=0.0, std=0.3591422140598297),\n",
    "                },\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        return builder(config)\n",
    "\n",
    "\n",
    "config = jmp_l_config()\n",
    "print(config)\n",
    "\n",
    "configs: list[tuple[PretrainConfig, type[PretrainModel]]] = []\n",
    "configs.append((config, PretrainModel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68389c622fed4ebd83964922c641af68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fast dev run:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:34:55] </span><span style=\"background-color: #800000; font-weight: bold\">CRITICAL</span> Setting                                                                          <a href=\"file:///workspaces/repositories/fm/src/ll/trainer/trainer.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">trainer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///workspaces/repositories/fm/src/ll/trainer/trainer.py#159\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">159</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         config.trainer.<span style=\"color: #808000; text-decoration-color: #808000\">default_root_dir</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'/workspaces/repositories/fm/config/pretrain/lig</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">htning_logs/a2p5cq6q'</span>.                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:34:55]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m Setting                                                                          \u001b]8;id=421020;file:///workspaces/repositories/fm/src/ll/trainer/trainer.py\u001b\\\u001b[2mtrainer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=651344;file:///workspaces/repositories/fm/src/ll/trainer/trainer.py#159\u001b\\\u001b[2m159\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         config.trainer.\u001b[33mdefault_root_dir\u001b[0m=\u001b[32m'/workspaces/repositories/fm/config/pretrain/lig\u001b[0m \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32mhtning_logs/a2p5cq6q'\u001b[0m.                                                           \u001b[2m              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"background-color: #800000; font-weight: bold\">CRITICAL</span> Set global seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.                                                                <a href=\"file:///workspaces/repositories/fm/src/ll/util/seed.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">seed.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///workspaces/repositories/fm/src/ll/util/seed.py#11\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m Set global seed to \u001b[1;36m0\u001b[0m.                                                                \u001b]8;id=271493;file:///workspaces/repositories/fm/src/ll/util/seed.py\u001b\\\u001b[2mseed.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=536110;file:///workspaces/repositories/fm/src/ll/util/seed.py#11\u001b\\\u001b[2m11\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"background-color: #800000; font-weight: bold\">CRITICAL</span> Auto-wrapping run in Trainer context                                              <a href=\"file:///workspaces/repositories/fm/src/ll/runner.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">runner.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///workspaces/repositories/fm/src/ll/runner.py#111\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">111</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m Auto-wrapping run in Trainer context                                              \u001b]8;id=499748;file:///workspaces/repositories/fm/src/ll/runner.py\u001b\\\u001b[2mrunner.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=375441;file:///workspaces/repositories/fm/src/ll/runner.py#111\u001b\\\u001b[2m111\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unrecognized arguments:  dict_keys(['learnable_rbf', 'learnable_rbf_stds', 'unique_basis_per_layer', 'dropout', 'edge_dropout'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:34:56] </span><span style=\"background-color: #800000; font-weight: bold\">CRITICAL</span> Disabling loggers because fast_dev_run is enabled.                               <a href=\"file:///workspaces/repositories/fm/src/ll/trainer/trainer.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">trainer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///workspaces/repositories/fm/src/ll/trainer/trainer.py#305\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">305</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:34:56]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m Disabling loggers because fast_dev_run is enabled.                               \u001b]8;id=146039;file:///workspaces/repositories/fm/src/ll/trainer/trainer.py\u001b\\\u001b[2mtrainer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=295528;file:///workspaces/repositories/fm/src/ll/trainer/trainer.py#305\u001b\\\u001b[2m305\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"background-color: #800000; font-weight: bold\">CRITICAL</span> Setting num_nodes to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"font-weight: bold\">(</span>no SLURM detected<span style=\"font-weight: bold\">)</span>.                                      <a href=\"file:///workspaces/repositories/fm/src/ll/trainer/trainer.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">trainer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///workspaces/repositories/fm/src/ll/trainer/trainer.py#336\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">336</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m Setting num_nodes to \u001b[1;36m1\u001b[0m \u001b[1m(\u001b[0mno SLURM detected\u001b[1m)\u001b[0m.                                      \u001b]8;id=262674;file:///workspaces/repositories/fm/src/ll/trainer/trainer.py\u001b\\\u001b[2mtrainer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=953938;file:///workspaces/repositories/fm/src/ll/trainer/trainer.py#336\u001b\\\u001b[2m336\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"background-color: #800000; font-weight: bold\">CRITICAL</span> LightningTrainer.__init__ with <span style=\"color: #808000; text-decoration-color: #808000\">args</span>=<span style=\"font-weight: bold\">()</span> and <span style=\"color: #808000; text-decoration-color: #808000\">kwargs</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'accelerator'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'auto'</span>,        <a href=\"file:///workspaces/repositories/fm/src/ll/trainer/trainer.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">trainer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///workspaces/repositories/fm/src/ll/trainer/trainer.py#360\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">360</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'strategy'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'auto'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'devices'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'auto'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'num_nodes'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'precision'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'16-mixed'</span>,  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'logger'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'fast_dev_run'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'max_epochs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'min_epochs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'max_steps'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'min_steps'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'max_time'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'limit_train_batches'</span>:     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'limit_val_batches'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'limit_test_batches'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'limit_predict_batches'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'overfit_batches'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'val_check_interval'</span>:     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'check_val_every_n_epoch'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'num_sanity_val_steps'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'log_every_n_steps'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'enable_checkpointing'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'enable_progress_bar'</span>:    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'enable_model_summary'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'accumulate_grad_batches'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'deterministic'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'benchmark'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'inference_mode'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'use_distributed_sampler'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'detect_anomaly'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'barebones'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'plugins'</span>: <span style=\"font-weight: bold\">[]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'sync_batchnorm'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reload_dataloaders_every_n_epochs'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'gradient_clip_algorithm'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'norm'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'gradient_clip_val'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'default_root_dir'</span>: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'/workspaces/repositories/fm/config/pretrain/lightning_logs/a2p5cq6q'</span>,           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'callbacks'</span>:                                                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"font-weight: bold\">[&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">lightning.pytorch.callbacks.on_exception_checkpoint.OnExceptionCheckpoint</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span>     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #000000; text-decoration-color: #000000\">object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7fe749a9c250</span><span style=\"font-weight: bold\">&gt;]}</span>.                                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m LightningTrainer.__init__ with \u001b[33margs\u001b[0m=\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m and \u001b[33mkwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'accelerator'\u001b[0m: \u001b[32m'auto'\u001b[0m,        \u001b]8;id=154100;file:///workspaces/repositories/fm/src/ll/trainer/trainer.py\u001b\\\u001b[2mtrainer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=325213;file:///workspaces/repositories/fm/src/ll/trainer/trainer.py#360\u001b\\\u001b[2m360\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'strategy'\u001b[0m: \u001b[32m'auto'\u001b[0m, \u001b[32m'devices'\u001b[0m: \u001b[32m'auto'\u001b[0m, \u001b[32m'num_nodes'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'precision'\u001b[0m: \u001b[32m'16-mixed'\u001b[0m,  \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'logger'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'fast_dev_run'\u001b[0m: \u001b[1;36m16\u001b[0m, \u001b[32m'max_epochs'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'min_epochs'\u001b[0m: \u001b[3;35mNone\u001b[0m,      \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'max_steps'\u001b[0m: \u001b[1;36m-1\u001b[0m, \u001b[32m'min_steps'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'max_time'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'limit_train_batches'\u001b[0m:     \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[3;35mNone\u001b[0m, \u001b[32m'limit_val_batches'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'limit_test_batches'\u001b[0m: \u001b[3;35mNone\u001b[0m,                     \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'limit_predict_batches'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'overfit_batches'\u001b[0m: \u001b[1;36m0.0\u001b[0m, \u001b[32m'val_check_interval'\u001b[0m:     \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[3;35mNone\u001b[0m, \u001b[32m'check_val_every_n_epoch'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'num_sanity_val_steps'\u001b[0m: \u001b[3;35mNone\u001b[0m,                \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'log_every_n_steps'\u001b[0m: \u001b[1;36m50\u001b[0m, \u001b[32m'enable_checkpointing'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'enable_progress_bar'\u001b[0m:    \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[3;35mNone\u001b[0m, \u001b[32m'enable_model_summary'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'accumulate_grad_batches'\u001b[0m: \u001b[1;36m1\u001b[0m,                \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'deterministic'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'benchmark'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'inference_mode'\u001b[0m: \u001b[3;92mTrue\u001b[0m,                \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'use_distributed_sampler'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'detect_anomaly'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'barebones'\u001b[0m: \u001b[3;91mFalse\u001b[0m,   \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'plugins'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'sync_batchnorm'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'reload_dataloaders_every_n_epochs'\u001b[0m: \u001b[1;36m0\u001b[0m,  \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'gradient_clip_algorithm'\u001b[0m: \u001b[32m'norm'\u001b[0m, \u001b[32m'gradient_clip_val'\u001b[0m: \u001b[1;36m1.0\u001b[0m, \u001b[32m'default_root_dir'\u001b[0m: \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'/workspaces/repositories/fm/config/pretrain/lightning_logs/a2p5cq6q'\u001b[0m,           \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'callbacks'\u001b[0m:                                                                     \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[1m[\u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mlightning.pytorch.callbacks.on_exception_checkpoint.OnExceptionCheckpoint\u001b[0m\u001b[39m \u001b[0m     \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[39mobject at \u001b[0m\u001b[1;36m0x7fe749a9c250\u001b[0m\u001b[1m>\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m.                                                     \u001b[2m              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 16 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> Logger DummyLogger does not support run_id, ignoring.                            <a href=\"file:///workspaces/repositories/fm/src/ll/trainer/logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///workspaces/repositories/fm/src/ll/trainer/logging.py#112\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Logger DummyLogger does not support run_id, ignoring.                            \u001b]8;id=346236;file:///workspaces/repositories/fm/src/ll/trainer/logging.py\u001b\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=495077;file:///workspaces/repositories/fm/src/ll/trainer/logging.py#112\u001b\\\u001b[2m112\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"background-color: #800000; font-weight: bold\">CRITICAL</span> LightningTrainer log directory: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>.                                            <a href=\"file:///workspaces/repositories/fm/src/ll/trainer/trainer.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">trainer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///workspaces/repositories/fm/src/ll/trainer/trainer.py#375\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">375</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m LightningTrainer log directory: \u001b[3;35mNone\u001b[0m.                                            \u001b]8;id=640561;file:///workspaces/repositories/fm/src/ll/trainer/trainer.py\u001b\\\u001b[2mtrainer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=671532;file:///workspaces/repositories/fm/src/ll/trainer/trainer.py#375\u001b\\\u001b[2m375\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/fm/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:126: `.fit(ckpt_path=None)` was called without a model. The last model of the previous `fit` call will be used. You can pass `fit(ckpt_path='best')` to use the best model or `fit(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "/opt/conda/envs/fm/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:186: .fit(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> Could not find wandb logger or module to log                                        <a href=\"file:///workspaces/repositories/fm/src/ll/model/modules/wandb.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">wandb.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///workspaces/repositories/fm/src/ll/model/modules/wandb.py#38\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Could not find wandb logger or module to log                                        \u001b]8;id=546678;file:///workspaces/repositories/fm/src/ll/model/modules/wandb.py\u001b\\\u001b[2mwandb.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=273145;file:///workspaces/repositories/fm/src/ll/model/modules/wandb.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"background-color: #800000; font-weight: bold\">CRITICAL</span> Fast dev run detected, setting debug flag to <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>.                                  <a href=\"file:///workspaces/repositories/fm/src/ll/model/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///workspaces/repositories/fm/src/ll/model/base.py#153\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">153</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m Fast dev run detected, setting debug flag to \u001b[3;92mTrue\u001b[0m.                                  \u001b]8;id=97802;file:///workspaces/repositories/fm/src/ll/model/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=754665;file:///workspaces/repositories/fm/src/ll/model/base.py#153\u001b\\\u001b[2m153\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"background-color: #800000; font-weight: bold\">CRITICAL</span> Optimizer: AdamW                                                                  <a href=\"file:///workspaces/repositories/fm/src/jmpfm/tasks/config.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">config.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///workspaces/repositories/fm/src/jmpfm/tasks/config.py#146\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">146</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         Optimizer kwargs: <span style=\"font-weight: bold\">{}</span>                                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         Base kwargs: <span style=\"font-weight: bold\">{}</span>                                                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         Param groups: Param group <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>:                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>             Params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">405</span>                                                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>             Total param size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">44131328</span>                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>             Other kwargs: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'lr'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0003</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'amsgrad'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'weight_decay'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'betas'</span>:  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'eps'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-08</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'foreach'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'maximize'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'capturable'</span>:      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'differentiable'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'fused'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m Optimizer: AdamW                                                                  \u001b]8;id=655638;file:///workspaces/repositories/fm/src/jmpfm/tasks/config.py\u001b\\\u001b[2mconfig.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=1198;file:///workspaces/repositories/fm/src/jmpfm/tasks/config.py#146\u001b\\\u001b[2m146\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         Optimizer kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                                                              \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         Base kwargs: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                                                                   \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         Param groups: Param group \u001b[1;36m0\u001b[0m:                                                      \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m             Params: \u001b[1;36m405\u001b[0m                                                                   \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m             Total param size: \u001b[1;36m44131328\u001b[0m                                                    \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m             Other kwargs: \u001b[1m{\u001b[0m\u001b[32m'lr'\u001b[0m: \u001b[1;36m0.0003\u001b[0m, \u001b[32m'amsgrad'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'weight_decay'\u001b[0m: \u001b[1;36m0.1\u001b[0m, \u001b[32m'betas'\u001b[0m:  \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[1m(\u001b[0m\u001b[1;36m0.9\u001b[0m, \u001b[1;36m0.95\u001b[0m\u001b[1m)\u001b[0m, \u001b[32m'eps'\u001b[0m: \u001b[1;36m1e-08\u001b[0m, \u001b[32m'foreach'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'maximize'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'capturable'\u001b[0m:      \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[3;91mFalse\u001b[0m, \u001b[32m'differentiable'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'fused'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m                                    \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "/opt/conda/envs/fm/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:34:57] </span><span style=\"background-color: #800000; font-weight: bold\">CRITICAL</span> Setting <span style=\"color: #808000; text-decoration-color: #808000\">max_steps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span> by default.                                                  <a href=\"file:///workspaces/repositories/fm/src/jmpfm/tasks/pretrain/module.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">module.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///workspaces/repositories/fm/src/jmpfm/tasks/pretrain/module.py#595\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">595</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:34:57]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m Setting \u001b[33mmax_steps\u001b[0m=\u001b[1;36m32\u001b[0m by default.                                                  \u001b]8;id=765752;file:///workspaces/repositories/fm/src/jmpfm/tasks/pretrain/module.py\u001b\\\u001b[2mmodule.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=341001;file:///workspaces/repositories/fm/src/jmpfm/tasks/pretrain/module.py#595\u001b\\\u001b[2m595\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | embedding     | Embedding        | 30.7 K\n",
      "1 | backbone      | GemNetOCBackbone | 38.8 M\n",
      "2 | output        | Output           | 5.3 M \n",
      "3 | train_metrics | FMMetrics        | 0     \n",
      "4 | val_metrics   | FMMetrics        | 0     \n",
      "5 | task_steps    | TypedModuleDict  | 0     \n",
      "---------------------------------------------------\n",
      "44.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "44.1 M    Total params\n",
      "176.525   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"background-color: #800000; font-weight: bold\">CRITICAL</span> Ignoring balancing because `ignore_balancing` is <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span> in                  <a href=\"file:///workspaces/repositories/fm/src/jmpfm/modules/dataset/concat_dataset.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">concat_dataset.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///workspaces/repositories/fm/src/jmpfm/modules/dataset/concat_dataset.py#245\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">245</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         `MTSampledDataset.__init__`.                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m Ignoring balancing because `ignore_balancing` is \u001b[3;92mTrue\u001b[0m in                  \u001b]8;id=232473;file:///workspaces/repositories/fm/src/jmpfm/modules/dataset/concat_dataset.py\u001b\\\u001b[2mconcat_dataset.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=250206;file:///workspaces/repositories/fm/src/jmpfm/modules/dataset/concat_dataset.py#245\u001b\\\u001b[2m245\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         `MTSampledDataset.__init__`.                                              \u001b[2m                     \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/fm/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d0f8049fdfc431ab752dd3ab43d7388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/fm/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2fd084ee9cd425faa8b7ce01572e584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=16` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:35:04] </span><span style=\"background-color: #800000; font-weight: bold\">CRITICAL</span> Ran <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> finalizers for Trainer cleanup.                                            <a href=\"file:///workspaces/repositories/fm/src/ll/trainer/trainer.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">trainer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///workspaces/repositories/fm/src/ll/trainer/trainer.py#223\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">223</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:35:04]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m Ran \u001b[1;36m1\u001b[0m finalizers for Trainer cleanup.                                            \u001b]8;id=95646;file:///workspaces/repositories/fm/src/ll/trainer/trainer.py\u001b\\\u001b[2mtrainer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=84353;file:///workspaces/repositories/fm/src/ll/trainer/trainer.py#223\u001b\\\u001b[2m223\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"background-color: #800000; font-weight: bold\">CRITICAL</span> Reset global seed.                                                                   <a href=\"file:///workspaces/repositories/fm/src/ll/util/seed.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">seed.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///workspaces/repositories/fm/src/ll/util/seed.py#17\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">17</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m Reset global seed.                                                                   \u001b]8;id=42450;file:///workspaces/repositories/fm/src/ll/util/seed.py\u001b\\\u001b[2mseed.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=271493;file:///workspaces/repositories/fm/src/ll/util/seed.py#17\u001b\\\u001b[2m17\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ll import Runner, Trainer\n",
    "\n",
    "\n",
    "def run(config: PretrainConfig, model_cls: type[PretrainModel]) -> None:\n",
    "    model = model_cls(config)\n",
    "    trainer = Trainer(config)\n",
    "    trainer.fit(model)\n",
    "\n",
    "runner = Runner(run)\n",
    "runner.fast_dev_run(configs, n_batches=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
